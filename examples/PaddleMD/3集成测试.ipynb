{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddleMD测试\n",
    "要在命令行测试，首先需要安装相关的库\n",
    "然后使用develop方式安装PaddleMD\n",
    "最后执行命令\n",
    "\n",
    "## 在notebook中安装moleculekit\n",
    "然后在命令行安装openmm\n",
    "`conda install openmm -c conda-forge -i https://mirror.baidu.com/pypi/simple`\n",
    "\n",
    "6.4日测试，发现需要使用`conda install openmm -c conda-forge`\n",
    "且安装的时候需要安装cuda\n",
    "\n",
    "## 测试记录：\n",
    "发现测试水分子的时候，很多值都没有变动。是不是没有反向传播的原因？\n",
    "\n",
    "综合测试的时候，Energy diff: 4.206e-08 Force diff 1.697e+00\n",
    "能量差值很小，而力场差别很大！ \n",
    "比如2watersperiodic： electrostatic Energy diff: 3.203e-06 Force diff: 1.695e+00\n",
    "静电力场差值很大！ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先安装需要的库\n",
    "openmm需要在命令行使用conda安装，moleculekit可以使用conda安装，也可以pip安装特定版本：\n",
    "```\n",
    "conda install openmm -c conda-forge\n",
    "conda install moleculekit -c acellera\n",
    "\n",
    "!pip install moleculekit==1.0.8 -i https://mirror.baidu.com/pypi/simple\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install moleculekit==1.0.8 -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装paddlemd开发模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: No names found, cannot describe anything.\n",
      "Could not get version tag. Defaulting to version 0\n",
      "running develop\n",
      "running egg_info\n",
      "writing paddlemd.egg-info/PKG-INFO\n",
      "writing dependency_links to paddlemd.egg-info/dependency_links.txt\n",
      "writing requirements to paddlemd.egg-info/requires.txt\n",
      "writing top-level names to paddlemd.egg-info/top_level.txt\n",
      "reading manifest file 'paddlemd.egg-info/SOURCES.txt'\n",
      "writing manifest file 'paddlemd.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "Creating /opt/conda/lib/python3.6/site-packages/paddlemd.egg-link (link to .)\n",
      "Adding paddlemd 0 to easy-install.pth file\n",
      "\n",
      "Installed /code/6paper/PaddleMD\n",
      "Processing dependencies for paddlemd==0\n",
      "error: pandas 0.24.2 is installed but pandas>=1.1.2 is required by {'moleculekit'}\n"
     ]
    }
   ],
   "source": [
    "!python setup.py develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始执行集合测试程序\n",
    "### 解决报错,把requires_grad改成stop_gradient\n",
    "\n",
    "### 效果尚可\n",
    "与openmm的差值为\n",
    "```\n",
    "Running test: test-data/thrombin-ligand-amber/\n",
    "  angle Energy diff: -5.433e-05 Force diff: 1.108e-03\n",
    "  bond Energy diff: 1.861e-04 Force diff: 4.413e-03\n",
    "  dihedral Energy diff: 3.932e-05 Force diff: 6.289e-04\n",
    "  lennardjones Energy diff: 1.829e-04 Force diff: 5.169e-04\n",
    "```\n",
    "gpu显存占用 4874MiB / 15109MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n",
      "/opt/conda/lib/python3.6/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "test_paddlemd (__main__._TestPaddleMD) ... \n",
      "Running test: test-data/4dihedrals/\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "W0606 00:00:46.058408 47490 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.0, Runtime API Version: 10.2\n",
      "W0606 00:00:46.066689 47490 gpu_context.cc:306] device: 0, cuDNN Version: 7.6.\n",
      "/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py:278: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.bool, the right dtype will convert to paddle.float32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "==line 423 of forces direction_vec.shape:[5, 3]\n",
      "==line 423 of forces direction_vec.shape:[6, 3]\n",
      "==line 423 of forces direction_vec.shape:[6, 3]\n",
      "==line 423 of forces direction_vec.shape:[4, 3]\n",
      "==line 423 of forces direction_vec.shape:[4, 3]\n",
      "==line 423 of forces direction_vec.shape:[4, 3]\n",
      "==line 423 of forces direction_vec.shape:[4, 3]\n",
      "==line 423 of forces direction_vec.shape:[3]\n",
      "\n",
      "Running test: test-data/thrombin-ligand-amber/\n",
      "==line 423 of forces direction_vec.shape:[4735, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12320, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[10904531, 3]\n",
      "  angle Energy diff: -5.433e-05 Force diff: 1.108e-03\n",
      "==line 423 of forces direction_vec.shape:[4735, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12320, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[10904531, 3]\n",
      "  bond Energy diff: 1.861e-04 Force diff: 4.413e-03\n",
      "==line 423 of forces direction_vec.shape:[4735, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12320, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[10904531, 3]\n",
      "  dihedral Energy diff: 3.932e-05 Force diff: 6.289e-04\n",
      "==line 423 of forces direction_vec.shape:[4735, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12320, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[10904531, 3]\n",
      "  lennardjones Energy diff: 1.829e-04 Force diff: 5.169e-04\n",
      "==line 423 of forces direction_vec.shape:[4735, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12320, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[958, 3]\n",
      "==line 423 of forces direction_vec.shape:[10904531, 3]\n",
      "  electrostatic Energy diff: 7.397e-03 Force diff: 1.873e-04\n",
      "==line 423 of forces direction_vec.shape:[4735, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[8564, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n",
      "==line 423 of forces direction_vec.shape:[12569, 3]\n"
     ]
    }
   ],
   "source": [
    "!python tests/test_paddlemd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 22:36:08,935 - moleculekit.readers - INFO - Attempting PDB query for 3ptb\n",
      "2022-06-04 22:36:12,998 - moleculekit.rcsb - WARNING - Failed to connect to URL https://files.rcsb.org/download/3ptb.pdb with error <urlopen error [Errno -3] Temporary failure in name resolution>. Sleeping 5s and retrying.\n"
     ]
    }
   ],
   "source": [
    "from moleculekit.molecule import Molecule\n",
    "\n",
    "mol = Molecule('3ptb')\n",
    "mol.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在命令行测试水分子\n",
    "\n",
    "执行命令为`./bin/paddlemd --conf tests/water/50000water_conf.yaml `\n",
    "\n",
    "torch下的速度7分36秒 飞桨下steps: 10大约23分钟\n",
    "现在1000step大约2分28秒,这样算下来50000step需要125分钟，大约2小时。 目前torchmd比paddlemd快16倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Force terms:  ['LJ', 'Bonds', 'Angles', 'Electrostatics']\n",
      "W0605 23:04:10.737171 27221 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.0, Runtime API Version: 10.2\n",
      "W0605 23:04:10.742141 27221 gpu_context.cc:306] device: 0, cuDNN Version: 7.6.\n",
      "/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py:278: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.bool, the right dtype will convert to paddle.float32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "Writing logs to  mywaterrun/monitor_0.csv\n",
      "Writing logs to  mywaterrun/monitor_1.csv\n",
      "100%|███████████████████████████████████████████| 20/20 [02:25<00:00,  7.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# !./bin/paddlemd --conf tests/water/50000water_conf.yaml # 10step 快速测试\n",
    "!./bin/paddlemd --conf tests/water/water_conf.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在命令行测试prod alanine dipeptide前丙氨酸二肽\n",
    "能跑下去，但是估计时间比较多。大约需要3.5小时。\n",
    "跑出来的数值跟torchmd接近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Force terms:  None\n",
      "2022-06-06 09:12:56,036 - root - WARNING - Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n",
      "W0606 09:12:58.064165  5913 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.0, Runtime API Version: 10.2\n",
      "W0606 09:12:58.067812  5913 gpu_context.cc:306] device: 0, cuDNN Version: 7.6.\n",
      "/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py:278: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.bool, the right dtype will convert to paddle.float32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "Writing logs to  /tmp/alanine_dipeptide/monitor_0.csv\n",
      "Iter  Epot            fmax    \n",
      "   0   -394.649102    94.587214\n",
      "   1   -244.550753    166.832696\n",
      "   2   -551.523092    52.779887\n",
      "   3   -625.534115    36.632183\n",
      "   4   -687.280235    30.542945\n",
      "   5   -733.957295    24.687908\n",
      "   6   -817.050362    24.721564\n",
      "   7   -754.431967    192.773101\n",
      "   8   -850.254271    70.142878\n",
      "   9   -901.241237    21.081346\n",
      "  10   -916.296138    18.886354\n",
      "  11   -936.405181    18.334992\n",
      "  12   -972.453569    27.532084\n",
      "  13   -990.593483    72.738474\n",
      "  14   -1017.250793    16.564241\n",
      "  15   -1024.191225    13.470535\n",
      "  16   -1032.751605    13.025528\n",
      "  17   -1048.537113    27.022897\n",
      "  18   -1065.972385    30.407535\n",
      "  19   -1079.823076    25.904237\n",
      "  20   -1087.684326    23.570845\n",
      "  21   -1093.869306    13.715810\n",
      "  22   -1100.369821    16.102986\n",
      "  23   -1110.324272    24.429892\n",
      "  24   -1115.231798    36.248622\n",
      "  25   -1121.942791    20.418163\n",
      "  26   -1126.746782    21.290997\n",
      "  27   -1130.165201    20.951644\n",
      "  28   -1134.683759    18.086220\n",
      "  29   -1139.817703    14.727351\n",
      "  30   -1144.531544    18.313526\n",
      "  31   -1149.338057    25.411136\n",
      "  32   -1153.852932    23.968390\n",
      "  33   -1157.693747    16.699052\n",
      "  34   -1161.537795    12.383870\n",
      "  35   -1164.056948    22.087893\n",
      "  36   -1167.450068    16.980205\n",
      "  37   -1171.687887    15.485776\n",
      "  38   -1174.575767    12.238370\n",
      "  39   -1177.364384    15.099172\n",
      "  40   -1180.114316    10.785314\n",
      "  41   -1183.043019    14.809877\n",
      "  42   -1185.321082    14.632764\n",
      "  43   -1187.232155    11.891699\n",
      "  44   -1190.048865    10.093625\n",
      "  45   -1192.442016    8.559513\n",
      "  46   -1195.139888    12.865176\n",
      "  47   -1197.729158    11.272464\n",
      "  48   -1199.689825    11.537266\n",
      "  49   -1201.746787    9.710245\n",
      "  50   -1204.277473    10.281892\n",
      "  51   -1205.863336    15.006948\n",
      "  52   -1207.701749    10.330508\n",
      "  53   -1209.439099    10.726596\n",
      "  54   -1211.519384    14.589495\n",
      "  55   -1213.092868    12.626761\n",
      "  56   -1214.923040    13.529813\n",
      "  57   -1217.215757    17.566866\n",
      "  58   -1218.530292    12.053341\n",
      "  59   -1219.930592    9.303538\n",
      "  60   -1221.999644    8.649031\n",
      "  61   -1223.287202    20.933591\n",
      "  62   -1224.876723    17.042545\n",
      "  63   -1227.061108    11.099514\n",
      "  64   -1227.969567    14.772843\n",
      "  65   -1228.859705    7.480876\n",
      "  66   -1229.920148    6.763900\n",
      "  67   -1231.150231    11.096092\n",
      "  68   -1232.808804    11.098512\n",
      "  69   -1234.470582    7.868622\n",
      "  70   -1235.521034    6.117880\n",
      "  71   -1236.465254    6.404703\n",
      "  72   -1237.752722    12.438302\n",
      "  73   -1239.377926    9.813759\n",
      "  74   -1240.803904    9.276748\n",
      "  75   -1241.861643    6.808124\n",
      "  76   -1242.756418    6.833408\n",
      "  77   -1243.943442    9.993585\n",
      "  78   -1245.378124    11.274136\n",
      "  79   -1246.663006    9.897424\n",
      "  80   -1247.868017    6.751109\n",
      "  81   -1249.147953    9.831200\n",
      "  82   -1249.958128    13.727317\n",
      "  83   -1250.797377    8.943069\n",
      "  84   -1252.139502    5.064890\n",
      "  85   -1253.002130    8.230582\n",
      "  86   -1253.685559    20.088936\n",
      "  87   -1255.060053    6.688974\n",
      "  88   -1255.699304    4.828917\n",
      "  89   -1256.508344    8.658668\n",
      "  90   -1257.763569    11.000842\n",
      "  91   -1259.077526    15.198385\n",
      "  92   -1260.196294    6.493098\n",
      "  93   -1261.287251    6.586633\n",
      "  94   -1262.110698    10.488997\n",
      "  95   -1263.280556    11.993452\n",
      "  96   -1264.302893    10.353645\n",
      "  97   -1265.225476    6.260116\n",
      "  98   -1266.056431    7.239553\n",
      "  99   -1266.698826    9.669202\n",
      " 100   -1267.491811    7.898193\n",
      " 101   -1268.838835    11.220644\n",
      " 102   -1269.744794    16.532186\n",
      " 103   -1270.697090    6.526730\n",
      " 104   -1271.275867    6.229226\n",
      " 105   -1271.879992    6.760279\n",
      " 106   -1272.873317    9.345710\n",
      " 107   -1273.985460    16.019303\n",
      " 108   -1275.079406    8.343336\n",
      " 109   -1275.912461    7.061625\n",
      " 110   -1276.644392    7.506033\n",
      " 111   -1277.519781    8.711743\n",
      " 112   -1278.344580    9.194270\n",
      " 113   -1279.132480    8.115626\n",
      " 114   -1279.782689    8.826125\n",
      " 115   -1280.517565    8.266730\n",
      " 116   -1281.449703    8.094932\n",
      " 117   -1282.309116    10.212950\n",
      " 118   -1283.133072    7.357760\n",
      " 119   -1283.938619    7.746208\n",
      " 120   -1284.846253    11.143240\n",
      " 121   -1285.709256    17.430804\n",
      " 122   -1286.487941    8.857230\n",
      " 123   -1286.980764    6.140481\n",
      " 124   -1287.488976    8.130957\n",
      " 125   -1288.350950    8.214983\n",
      " 126   -1289.064458    9.004233\n",
      " 127   -1289.675579    6.506435\n",
      " 128   -1290.545912    9.235545\n",
      " 129   -1291.242622    10.643581\n",
      " 130   -1292.011218    9.254505\n",
      " 131   -1292.558334    6.064275\n",
      " 132   -1293.055194    7.430083\n",
      " 133   -1293.683077    7.951971\n",
      " 134   -1294.536564    14.502345\n",
      " 135   -1295.378233    8.196169\n",
      " 136   -1295.905151    5.970431\n",
      " 137   -1296.551886    7.615332\n",
      " 138   -1297.198849    11.600924\n",
      " 139   -1297.988731    8.059015\n",
      " 140   -1298.837136    9.074794\n",
      " 141   -1299.363165    12.242724\n",
      " 142   -1299.937893    6.062454\n",
      " 143   -1300.410587    4.404014\n",
      " 144   -1300.947802    6.846402\n",
      " 145   -1301.662104    10.508380\n",
      " 146   -1302.573097    9.443419\n",
      " 147   -1303.206683    6.221531\n",
      " 148   -1303.633703    7.890635\n",
      " 149   -1304.114102    7.991770\n",
      " 150   -1304.871853    6.171746\n",
      " 151   -1305.392358    10.446249\n",
      " 152   -1305.965491    8.098032\n",
      " 153   -1306.603007    6.265957\n",
      " 154   -1307.146423    8.739183\n",
      " 155   -1307.625488    5.552261\n",
      " 156   -1308.108121    6.498011\n",
      " 157   -1308.603757    6.945806\n",
      " 158   -1309.041582    7.132010\n",
      " 159   -1309.461280    7.291922\n",
      " 160   -1309.813035    4.540438\n",
      " 161   -1310.389557    8.063000\n",
      " 162   -1310.596911    14.144388\n",
      " 163   -1311.204268    7.731963\n",
      " 164   -1311.523546    4.142690\n",
      " 165   -1311.847292    7.679177\n",
      " 166   -1312.334145    11.147472\n",
      " 167   -1312.912984    8.987253\n",
      " 168   -1313.489743    6.417299\n",
      " 169   -1313.873851    5.127744\n",
      " 170   -1314.266517    6.183403\n",
      " 171   -1314.972138    13.115843\n",
      " 172   -1315.727852    8.507727\n",
      " 173   -1316.331742    6.870392\n",
      " 174   -1316.911080    8.272568\n",
      " 175   -1317.258425    11.449973\n",
      " 176   -1317.607871    4.734472\n",
      " 177   -1317.974406    6.303063\n",
      " 178   -1318.375136    7.373204\n",
      " 179   -1319.019572    12.791473\n",
      " 180   -1319.640654    7.329557\n",
      " 181   -1319.997048    7.149543\n",
      " 182   -1320.345821    6.370917\n",
      " 183   -1320.724795    5.723717\n",
      " 184   -1321.282830    10.716098\n",
      " 185   -1321.816604    6.124665\n",
      " 186   -1322.268953    6.585639\n",
      " 187   -1322.781167    9.243698\n",
      " 188   -1323.178978    17.157090\n",
      " 189   -1323.622065    8.511349\n",
      " 190   -1323.925346    5.315737\n",
      " 191   -1324.216838    4.880474\n",
      " 192   -1324.760061    9.759534\n",
      " 193   -1324.982868    16.845997\n",
      " 194   -1325.537910    4.276791\n",
      " 195   -1325.754056    3.776431\n",
      " 196   -1326.037675    4.022524\n",
      " 197   -1326.536640    9.874792\n",
      " 198   -1326.851231    25.836729\n",
      " 199   -1327.401396    5.682565\n",
      " 200   -1327.647523    3.864683\n",
      " 201   -1327.907170    8.746447\n",
      " 202   -1328.226064    6.307708\n",
      " 203   -1328.655810    9.992402\n",
      " 204   -1329.231860    3.892931\n",
      " 205   -1329.526902    3.719337\n",
      " 206   -1329.868760    8.719571\n",
      " 207   -1330.181898    10.937251\n",
      " 208   -1330.539219    4.548563\n",
      " 209   -1330.904467    7.252211\n",
      " 210   -1331.187035    4.929201\n",
      " 211   -1331.567283    6.476486\n",
      " 212   -1331.851485    6.086423\n",
      " 213   -1332.140086    4.919037\n",
      " 214   -1332.470708    5.463445\n",
      " 215   -1332.842400    8.415549\n",
      " 216   -1333.155083    6.894108\n",
      " 217   -1333.356734    5.481032\n",
      " 218   -1333.600207    3.590003\n",
      " 219   -1333.857299    4.635473\n",
      " 220   -1334.134578    10.768338\n",
      " 221   -1334.451618    6.173341\n",
      " 222   -1334.676847    3.436568\n",
      " 223   -1334.900050    3.934644\n",
      " 224   -1335.138751    7.722255\n",
      " 225   -1335.455505    5.610544\n",
      " 226   -1335.793963    4.469209\n",
      " 227   -1336.040961    5.071013\n",
      " 228   -1336.297422    6.975325\n",
      " 229   -1336.525966    4.549597\n",
      " 230   -1336.825171    4.638265\n",
      " 231   -1337.040296    4.937002\n",
      " 232   -1337.278423    4.242797\n",
      " 233   -1337.475574    3.995329\n",
      " 234   -1337.620577    4.825510\n",
      " 235   -1337.794346    4.691986\n",
      " 236   -1338.041152    4.068250\n",
      " 237   -1338.253251    5.305205\n",
      " 238   -1338.493893    4.361387\n",
      " 239   -1338.713216    5.497297\n",
      " 240   -1338.981069    5.308985\n",
      " 241   -1339.194242    4.740512\n",
      " 242   -1339.388512    3.725810\n",
      " 243   -1339.618829    5.755655\n",
      " 244   -1339.771159    4.576222\n",
      " 245   -1339.929986    3.529679\n",
      " 246   -1340.217356    7.006971\n",
      " 247   -1340.451431    4.495710\n",
      " 248   -1340.576787    3.057359\n",
      " 249   -1340.719591    2.775859\n",
      " 250   -1340.929943    3.082743\n",
      " 251   -1341.104954    5.943065\n",
      " 252   -1341.298026    3.597972\n",
      " 253   -1341.546828    3.869396\n",
      " 254   -1341.775690    5.061633\n",
      " 255   -1342.003772    4.903590\n",
      " 256   -1342.189465    2.496749\n",
      " 257   -1342.392185    4.504535\n",
      " 258   -1342.620712    6.612764\n",
      " 259   -1342.864464    7.836897\n",
      " 260   -1343.089716    10.717855\n",
      " 261   -1343.256992    6.564449\n",
      " 262   -1343.378634    4.206593\n",
      " 263   -1343.689603    4.287867\n",
      " 264   -1343.897747    7.597852\n",
      " 265   -1344.200570    6.432026\n",
      " 266   -1344.520020    5.242047\n",
      " 267   -1344.739674    8.941396\n",
      " 268   -1344.992216    4.732939\n",
      " 269   -1345.310498    5.370279\n",
      " 270   -1345.528187    8.943323\n",
      " 271   -1345.799666    6.134395\n",
      " 272   -1346.044491    4.704412\n",
      " 273   -1346.230472    6.247663\n",
      " 274   -1346.413027    5.591328\n",
      " 275   -1346.620255    4.103773\n",
      " 276   -1346.849891    4.194125\n",
      " 277   -1347.019140    3.698402\n",
      " 278   -1347.245113    4.132503\n",
      " 279   -1347.440345    6.419781\n",
      " 280   -1347.624780    4.082751\n",
      " 281   -1347.772575    3.942767\n",
      " 282   -1347.979429    5.760532\n",
      " 283   -1348.124004    6.509028\n",
      " 284   -1348.240934    3.929243\n",
      " 285   -1348.382440    3.223498\n",
      " 286   -1348.521191    5.197007\n",
      " 287   -1348.629454    9.140160\n",
      " 288   -1348.804489    3.806155\n",
      " 289   -1348.888842    3.565390\n",
      " 290   -1349.034881    4.794820\n",
      " 291   -1349.192615    8.684421\n",
      " 292   -1349.363542    5.236846\n",
      " 293   -1349.459536    2.415242\n",
      " 294   -1349.559839    3.893854\n",
      " 295   -1349.688435    6.044961\n",
      " 296   -1349.881561    5.677209\n",
      " 297   -1350.052735    4.418672\n",
      " 298   -1350.213157    3.387816\n",
      " 299   -1350.305422    3.088521\n",
      " 300   -1350.455349    4.585647\n",
      " 301   -1350.626921    5.243615\n",
      " 302   -1350.780414    5.495448\n",
      " 303   -1350.991513    5.081421\n",
      " 304   -1351.055808    10.284078\n",
      " 305   -1351.177176    3.522047\n",
      " 306   -1351.274153    2.094054\n",
      " 307   -1351.374398    4.199573\n",
      " 308   -1351.563721    6.321741\n",
      " 309   -1351.561841    8.322523\n",
      " 310   -1351.688480    5.321647\n",
      " 311   -1351.884470    3.175766\n",
      " 312   -1352.018026    2.202522\n",
      " 313   -1352.152937    4.197136\n",
      " 314   -1352.305982    5.538958\n",
      " 315   -1352.484262    4.793210\n",
      " 316   -1352.626357    3.191786\n",
      " 317   -1352.720685    2.276095\n",
      " 318   -1352.862029    5.145657\n",
      " 319   -1352.992820    8.831632\n",
      " 320   -1353.161794    4.050647\n",
      " 321   -1353.325407    2.579984\n",
      " 322   -1353.397361    4.417030\n",
      " 323   -1353.472656    3.393110\n",
      " 324   -1353.723390    3.175742\n",
      " 325   -1353.881122    4.578671\n",
      " 326   -1354.055102    3.042609\n",
      " 327   -1354.145650    4.084482\n",
      " 328   -1354.230103    2.708554\n",
      " 329   -1354.371625    2.861343\n",
      " 330   -1354.513000    7.746753\n",
      " 331   -1354.674397    4.253999\n",
      " 332   -1354.826541    2.771846\n",
      " 333   -1354.921793    2.887763\n",
      " 334   -1355.018002    2.455551\n",
      " 335   -1355.137482    2.521784\n",
      " 336   -1355.270493    3.191508\n",
      " 337   -1355.352935    8.786734\n",
      " 338   -1355.505647    2.973075\n",
      " 339   -1355.593217    2.249246\n",
      " 340   -1355.704293    3.033150\n",
      " 341   -1355.769998    8.581776\n",
      " 342   -1355.936489    3.485052\n",
      " 343   -1356.016501    2.111942\n",
      " 344   -1356.125553    3.068624\n",
      " 345   -1356.277983    3.209005\n",
      " 346   -1356.162667    9.926125\n",
      " 347   -1356.362643    4.816050\n",
      " 348   -1356.494442    3.115012\n",
      " 349   -1356.593277    2.185547\n",
      " 350   -1356.711793    5.377014\n",
      " 351   -1356.834879    2.975560\n",
      " 352   -1356.991317    3.752119\n",
      " 353   -1357.093812    3.915496\n",
      " 354   -1357.200599    2.483189\n",
      " 355   -1357.295117    2.167912\n",
      " 356   -1357.416981    3.432964\n",
      " 357   -1357.481533    6.648864\n",
      " 358   -1357.627075    2.888499\n",
      " 359   -1357.681655    1.808385\n",
      " 360   -1357.751039    3.207198\n",
      " 361   -1357.874073    4.942267\n",
      " 362   -1357.997114    5.352519\n",
      " 363   -1358.124570    2.366436\n",
      " 364   -1358.194803    2.088698\n",
      " 365   -1358.281153    3.595331\n",
      " 366   -1358.403565    5.625768\n",
      " 367   -1358.539034    3.289231\n",
      " 368   -1358.669512    4.008909\n",
      " 369   -1358.785823    3.918201\n",
      " 370   -1358.886863    5.372106\n",
      " 371   -1359.017307    3.031212\n",
      " 372   -1359.121905    8.066990\n",
      " 373   -1359.241391    2.902657\n",
      " 374   -1359.322629    2.389011\n",
      " 375   -1359.465862    5.869133\n",
      " 376   -1359.574740    4.762139\n",
      " 377   -1359.709322    3.149011\n",
      " 378   -1359.890050    2.618049\n",
      " 379   -1360.015478    3.496290\n",
      " 380   -1360.095735    6.517911\n",
      " 381   -1360.294223    3.205814\n",
      " 382   -1360.371749    1.944878\n",
      " 383   -1360.479746    2.540508\n",
      " 384   -1360.558359    16.447428\n",
      " 385   -1360.725976    4.703728\n",
      " 386   -1360.863112    3.024738\n",
      " 387   -1360.995317    2.651022\n",
      " 388   -1361.153664    3.550203\n",
      " 389   -1361.224927    7.439652\n",
      " 390   -1361.389458    4.022317\n",
      " 391   -1361.460332    1.951221\n",
      " 392   -1361.559265    2.331997\n",
      " 393   -1361.697782    8.152359\n",
      " 394   -1361.852317    5.428213\n",
      " 395   -1361.982591    2.623389\n",
      " 396   -1362.080998    2.960149\n",
      " 397   -1362.167118    2.750342\n",
      " 398   -1362.241538    2.831693\n",
      " 399   -1362.341561    2.671471\n",
      " 400   -1362.407903    4.075751\n",
      " 401   -1362.483297    2.594481\n",
      " 402   -1362.587145    2.849694\n",
      " 403   -1362.647554    2.689017\n",
      " 404   -1362.760942    3.358247\n",
      " 405   -1362.856878    3.985402\n",
      " 406   -1362.951968    2.596247\n",
      " 407   -1363.056119    3.574639\n",
      " 408   -1363.129911    2.908251\n",
      " 409   -1363.226435    3.074937\n",
      " 410   -1363.316712    3.775815\n",
      " 411   -1363.425136    4.323303\n",
      " 412   -1363.502139    3.246945\n",
      " 413   -1363.581265    2.785095\n",
      " 414   -1363.666205    3.654576\n",
      " 415   -1363.777781    4.956724\n",
      " 416   -1363.880239    3.721627\n",
      " 417   -1363.954788    3.023144\n",
      " 418   -1364.040117    2.868946\n",
      " 419   -1364.106169    7.985760\n",
      " 420   -1364.180388    2.939864\n",
      " 421   -1364.240578    2.111203\n",
      " 422   -1364.305867    3.123406\n",
      " 423   -1364.386058    4.187772\n",
      " 424   -1364.466534    3.151006\n",
      " 425   -1364.546472    2.151447\n",
      " 426   -1364.628862    3.140275\n",
      " 427   -1364.708264    3.075127\n",
      " 428   -1364.775585    2.568925\n",
      " 429   -1364.878660    2.831468\n",
      " 430   -1364.964337    3.860640\n",
      " 431   -1365.045977    2.258521\n",
      " 432   -1365.102002    1.925133\n",
      " 433   -1365.145082    4.149407\n",
      " 434   -1365.216679    2.249816\n",
      " 435   -1365.322162    4.287076\n",
      " 436   -1365.431958    3.040236\n",
      " 437   -1365.492019    2.360409\n",
      " 438   -1365.591263    3.352616\n",
      " 439   -1365.651382    4.677845\n",
      " 440   -1365.721347    3.557721\n",
      " 441   -1365.800790    2.324689\n",
      " 442   -1365.866531    2.374886\n",
      " 443   -1365.951616    6.250492\n",
      " 444   -1366.040112    3.615956\n",
      " 445   -1366.103480    2.553799\n",
      " 446   -1366.200749    2.848541\n",
      " 447   -1366.314553    5.266060\n",
      " 448   -1366.430482    3.378151\n",
      " 449   -1366.495722    2.210218\n",
      " 450   -1366.569671    1.934680\n",
      " 451   -1366.663130    4.640565\n",
      " 452   -1366.767372    3.800430\n",
      " 453   -1366.877931    3.186146\n",
      " 454   -1366.950958    3.022561\n",
      " 455   -1367.023551    2.500628\n",
      " 456   -1367.133607    3.745132\n",
      " 457   -1367.229692    3.474084\n",
      " 458   -1367.335271    2.976537\n",
      " 459   -1367.421295    2.665771\n",
      " 460   -1367.496211    2.815883\n",
      " 461   -1367.613049    4.275870\n",
      " 462   -1367.699962    4.395701\n",
      " 463   -1367.796817    2.580123\n",
      " 464   -1367.906915    2.167660\n",
      " 465   -1367.988436    3.340063\n",
      " 466   -1368.073731    3.346951\n",
      " 467   -1368.160439    2.393230\n",
      " 468   -1368.246241    4.200929\n",
      " 469   -1368.331077    3.433588\n",
      " 470   -1368.409642    2.736650\n",
      " 471   -1368.482138    3.417695\n",
      " 472   -1368.558976    3.054231\n",
      " 473   -1368.638870    3.130462\n",
      " 474   -1368.731062    2.941599\n",
      " 475   -1368.772802    2.461492\n",
      " 476   -1368.849704    1.729004\n",
      " 477   -1368.906161    1.864690\n",
      " 478   -1368.969451    3.002787\n",
      " 479   -1369.071342    3.702021\n",
      " 480   -1369.159560    3.520064\n",
      " 481   -1369.232484    1.870357\n",
      " 482   -1369.286722    2.494903\n",
      " 483   -1369.349147    3.215401\n",
      " 484   -1369.464179    4.785766\n",
      " 485   -1369.565354    2.632817\n",
      " 486   -1369.631181    2.110993\n",
      " 487   -1369.685314    2.354689\n",
      " 488   -1369.738822    3.000462\n",
      " 489   -1369.790731    1.822060\n",
      " 490   -1369.876474    2.966644\n",
      " 491   -1369.932181    3.435599\n",
      " 492   -1370.000061    2.552972\n",
      " 493   -1370.071910    4.298189\n",
      " 494   -1370.134100    3.349828\n",
      " 495   -1370.177418    2.437000\n",
      " 496   -1370.272196    3.144913\n",
      " 497   -1370.313722    4.878898\n",
      " 498   -1370.364687    2.008176\n",
      " 499   -1370.411303    1.427393\n",
      " 500   -1370.460784    1.966220\n",
      " 501   -1370.530529    5.858995\n",
      " 502   -1370.602966    2.109530\n",
      " 503   -1370.646536    1.302353\n",
      " 504   -1370.701099    1.901180\n",
      " 505   -1370.740308    3.079475\n",
      " 506   -1370.794574    2.518886\n",
      " 507   -1370.857395    1.938004\n",
      " 508   -1370.888380    1.603799\n",
      " 509   -1370.921708    1.263743\n",
      " 510   -1370.980177    2.932906\n",
      " 511   -1371.023911    2.331590\n",
      " 512   -1371.048209    1.618171\n",
      " 513   -1371.109905    1.172644\n",
      " 514   -1371.134134    2.943817\n",
      " 515   -1371.166136    2.278552\n",
      " 516   -1371.218949    1.836243\n",
      " 517   -1371.254729    1.615891\n",
      " 518   -1371.290196    2.075131\n",
      " 519   -1371.318345    1.202033\n",
      " 520   -1371.339391    1.547699\n",
      " 521   -1371.375703    1.697053\n",
      " 522   -1371.412242    5.149765\n",
      " 523   -1371.459544    2.155685\n",
      " 524   -1371.491346    1.765573\n",
      " 525   -1371.516864    1.698706\n",
      " 526   -1371.550391    3.040559\n",
      " 527   -1371.591882    2.073385\n",
      " 528   -1371.618577    2.837332\n",
      " 529   -1371.661891    1.491074\n",
      " 530   -1371.679534    1.226440\n",
      " 531   -1371.729784    2.024637\n",
      " 532   -1371.738281    5.804022\n",
      " 533   -1371.808143    2.484419\n",
      " 534   -1371.834743    1.639693\n",
      " 535   -1371.876540    1.913940\n",
      " 536   -1371.922843    2.739126\n",
      " 537   -1371.977991    2.629543\n",
      " 538   -1372.037238    2.485736\n",
      " 539   -1372.099210    1.745911\n",
      " 540   -1372.155152    2.111172\n",
      " 541   -1372.210046    2.896162\n",
      " 542   -1372.270026    2.261924\n",
      " 543   -1372.332156    2.910704\n",
      " 544   -1372.401032    2.531211\n",
      " 545   -1372.458579    5.945356\n",
      " 546   -1372.519245    3.442074\n",
      " 547   -1372.589988    2.392568\n",
      " 548   -1372.661242    3.468271\n",
      " 549   -1372.710939    2.823857\n",
      " 550   -1372.763532    2.587939\n",
      " 551   -1372.810021    1.925335\n",
      " 552   -1372.855972    2.046531\n",
      " 553   -1372.931905    2.644757\n",
      " 554   -1372.995736    3.950394\n",
      " 555   -1373.048948    2.179009\n",
      " 556   -1373.092913    2.153909\n",
      " 557   -1373.132146    2.918840\n",
      " 558   -1373.186890    3.051487\n",
      " 559   -1373.233049    4.780256\n",
      " 560   -1373.268127    1.497953\n",
      " 561   -1373.301230    2.255631\n",
      " 562   -1373.336819    3.774723\n",
      " 563   -1373.390970    2.117309\n",
      " 564   -1373.438809    3.791092\n",
      " 565   -1373.487040    1.500075\n",
      " 566   -1373.515013    1.686313\n",
      " 567   -1373.544425    1.638813\n",
      " 568   -1373.588713    2.023747\n",
      " 569   -1373.635486    2.525899\n",
      " 570   -1373.677376    2.675711\n",
      " 571   -1373.715728    1.888652\n",
      " 572   -1373.748575    3.758209\n",
      " 573   -1373.791564    2.367727\n",
      " 574   -1373.826899    2.304093\n",
      " 575   -1373.862507    1.794751\n",
      " 576   -1373.897029    2.329113\n",
      " 577   -1373.948401    2.662568\n",
      " 578   -1373.991967    3.043770\n",
      " 579   -1374.027108    2.024802\n",
      " 580   -1374.060842    1.392474\n",
      " 581   -1374.118153    2.203730\n",
      " 582   -1374.138594    2.561547\n",
      " 583   -1374.176489    1.584226\n",
      " 584   -1374.205709    1.310828\n",
      " 585   -1374.241100    1.697905\n",
      " 586   -1374.293653    2.785172\n",
      " 587   -1374.289843    9.620294\n",
      " 588   -1374.329097    3.344506\n",
      " 589   -1374.373985    1.860788\n",
      " 590   -1374.411443    1.658545\n",
      " 591   -1374.446553    1.673090\n",
      " 592   -1374.480323    3.802400\n",
      " 593   -1374.523755    1.370857\n",
      " 594   -1374.547014    1.091450\n",
      " 595   -1374.574125    1.634973\n",
      " 596   -1374.624234    2.843029\n",
      " 597   -1374.585737    4.420555\n",
      " 598   -1374.646303    2.149484\n",
      " 599   -1374.693679    1.619766\n",
      " 600   -1374.740560    1.802694\n",
      " 601   -1374.773363    2.583508\n",
      " 602   -1374.807221    2.366478\n",
      " 603   -1374.843358    1.740958\n",
      " 604   -1374.871491    1.602848\n",
      " 605   -1374.897400    1.811261\n",
      " 606   -1374.926171    2.060174\n",
      " 607   -1374.967327    2.216772\n",
      " 608   -1374.982909    4.650540\n",
      " 609   -1375.035203    1.217259\n",
      " 610   -1375.053876    0.930820\n",
      " 611   -1375.078948    1.669472\n",
      " 612   -1375.112768    2.335858\n",
      " 613   -1375.157513    2.150466\n",
      " 614   -1375.200644    1.640262\n",
      " 615   -1375.243741    2.215850\n",
      " 616   -1375.276586    2.277195\n",
      " 617   -1375.303273    1.703574\n",
      " 618   -1375.343270    1.428006\n",
      " 619   -1375.372491    1.875191\n",
      " 620   -1375.404766    1.852040\n",
      " 621   -1375.460609    1.606620\n",
      " 622   -1375.484535    1.374395\n",
      " 623   -1375.515580    1.370664\n",
      " 624   -1375.549815    3.145159\n",
      " 625   -1375.593629    1.532533\n",
      " 626   -1375.611148    1.383815\n",
      " 627   -1375.653730    1.549388\n",
      " 628   -1375.645822    4.606054\n",
      " 629   -1375.672163    2.110046\n",
      " 630   -1375.695347    1.641027\n",
      " 631   -1375.742226    2.046192\n",
      " 632   -1375.767598    2.627844\n",
      " 633   -1375.801838    1.701227\n",
      " 634   -1375.835974    1.282936\n",
      " 635   -1375.863798    1.794512\n",
      " 636   -1375.897295    2.362095\n",
      " 637   -1375.928207    1.632572\n",
      " 638   -1375.956969    1.214612\n",
      " 639   -1375.993780    1.765818\n",
      " 640   -1375.998776    2.837263\n",
      " 641   -1376.046742    1.232897\n",
      " 642   -1376.062447    1.066238\n",
      " 643   -1376.084695    1.114495\n",
      " 644   -1376.123849    1.595885\n",
      " 645   -1376.160522    2.157432\n",
      " 646   -1376.197237    1.274428\n",
      " 647   -1376.221840    0.994087\n",
      " 648   -1376.246574    1.240358\n",
      " 649   -1376.274172    2.494634\n",
      " 650   -1376.304408    1.464215\n",
      " 651   -1376.327897    1.234499\n",
      " 652   -1376.348222    1.070658\n",
      " 653   -1376.373260    2.077276\n",
      " 654   -1376.399745    1.734861\n",
      " 655   -1376.426718    1.707199\n",
      " 656   -1376.450906    2.221469\n",
      " 657   -1376.474982    1.251762\n",
      " 658   -1376.486052    1.508165\n",
      " 659   -1376.510926    2.038959\n",
      " 660   -1376.541320    2.345604\n",
      " 661   -1376.572757    0.961665\n",
      " 662   -1376.593840    1.191107\n",
      " 663   -1376.607502    1.385515\n",
      " 664   -1376.634812    1.277133\n",
      " 665   -1376.663494    1.971995\n",
      " 666   -1376.694395    1.271336\n",
      " 667   -1376.711063    1.069724\n",
      " 668   -1376.727378    0.989760\n",
      " 669   -1376.746342    1.985052\n",
      " 670   -1376.771782    1.488325\n",
      " 671   -1376.792656    1.571856\n",
      " 672   -1376.812328    1.160289\n",
      " 673   -1376.829196    1.203855\n",
      " 674   -1376.863798    1.641482\n",
      " 675   -1376.886371    2.496999\n",
      " 676   -1376.912521    1.724940\n",
      " 677   -1376.935385    1.088461\n",
      " 678   -1376.952481    1.029081\n",
      " 679   -1376.975010    3.797376\n",
      " 680   -1377.000897    1.812911\n",
      " 681   -1377.016843    1.296039\n",
      " 682   -1377.045562    1.723635\n",
      " 683   -1377.066093    4.302859\n",
      " 684   -1377.092385    2.487897\n",
      " 685   -1377.120822    1.248455\n",
      " 686   -1377.139418    1.609738\n",
      " 687   -1377.177908    3.235426\n",
      " 688   -1377.202445    2.605652\n",
      " 689   -1377.238051    1.807034\n",
      " 690   -1377.260115    1.147771\n",
      " 691   -1377.279660    1.230305\n",
      " 692   -1377.307546    3.333834\n",
      " 693   -1377.353948    2.352801\n",
      " 694   -1377.384742    1.906914\n",
      " 695   -1377.422386    1.695945\n",
      " 696   -1377.437861    3.627663\n",
      " 697   -1377.488758    1.636673\n",
      " 698   -1377.522319    1.076329\n",
      " 699   -1377.549731    1.677144\n",
      " 700   -1377.602364    2.706257\n",
      " 701   -1377.604154    2.619081\n",
      " 702   -1377.680514    1.563360\n",
      " 703   -1377.701780    1.059276\n",
      " 704   -1377.732391    1.179403\n",
      " 705   -1377.769941    3.076065\n",
      " 706   -1377.811689    1.981728\n",
      " 707   -1377.844656    1.809384\n",
      " 708   -1377.894595    2.139176\n",
      " 709   -1377.937620    2.477671\n",
      " 710   -1377.983612    1.845832\n",
      " 711   -1378.039897    2.278776\n",
      " 712   -1378.071347    1.878507\n",
      " 713   -1378.100370    1.195707\n",
      " 714   -1378.171595    3.059489\n",
      " 715   -1378.204520    2.825550\n",
      " 716   -1378.245217    2.056337\n",
      " 717   -1378.267581    5.939776\n",
      " 718   -1378.326722    2.350069\n",
      " 719   -1378.341974    2.069370\n",
      " 720   -1378.401628    3.296746\n",
      " 721   -1378.448306    3.950194\n",
      " 722   -1378.496431    2.116040\n",
      " 723   -1378.532422    1.622784\n",
      " 724   -1378.565722    1.897075\n",
      " 725   -1378.614768    3.408556\n",
      " 726   -1378.673437    2.495335\n",
      " 727   -1378.717254    2.089483\n",
      " 728   -1378.771224    1.334120\n",
      " 729   -1378.802093    2.125327\n",
      " 730   -1378.831295    1.872011\n",
      " 731   -1378.887407    3.362586\n",
      " 732   -1378.916681    4.343045\n",
      " 733   -1378.961011    2.021460\n",
      " 734   -1379.013157    1.626353\n",
      " 735   -1379.046900    1.698943\n",
      " 736   -1379.081611    4.264888\n",
      " 737   -1379.140002    1.544042\n",
      " 738   -1379.163788    1.513964\n",
      " 739   -1379.196700    1.564859\n",
      " 740   -1379.235609    2.363194\n",
      " 741   -1379.274662    1.611227\n",
      " 742   -1379.303146    1.549466\n",
      " 743   -1379.349031    1.856498\n",
      " 744   -1379.378508    2.029551\n",
      " 745   -1379.404440    1.645841\n",
      " 746   -1379.434629    1.285553\n",
      " 747   -1379.453591    1.383992\n",
      " 748   -1379.509694    3.039008\n",
      " 749   -1379.540009    2.863661\n",
      " 750   -1379.571854    1.888371\n",
      " 751   -1379.599344    1.063314\n",
      " 752   -1379.619406    1.196555\n",
      " 753   -1379.650996    2.410308\n",
      " 754   -1379.678249    2.219646\n",
      " 755   -1379.700170    1.531802\n",
      " 756   -1379.741890    1.397779\n",
      " 757   -1379.771471    1.789265\n",
      " 758   -1379.805311    1.912019\n",
      " 759   -1379.841174    1.598166\n",
      " 760   -1379.871928    1.326274\n",
      " 761   -1379.895171    1.287932\n",
      " 762   -1379.927920    2.551053\n",
      " 763   -1379.961353    1.933508\n",
      " 764   -1379.983711    1.131612\n",
      " 765   -1380.018388    1.684346\n",
      " 766   -1380.032465    3.950496\n",
      " 767   -1380.056236    1.924571\n",
      " 768   -1380.078806    1.247803\n",
      " 769   -1380.099029    1.689653\n",
      " 770   -1380.118798    4.108937\n",
      " 771   -1380.157377    1.733031\n",
      " 772   -1380.172300    0.926733\n",
      " 773   -1380.188752    1.755133\n",
      " 774   -1380.214422    3.752807\n",
      " 775   -1380.246422    3.163456\n",
      " 776   -1380.277642    1.761458\n",
      " 777   -1380.296242    2.246723\n",
      " 778   -1380.312800    2.435537\n",
      " 779   -1380.332302    1.916375\n",
      " 780   -1380.368271    2.033514\n",
      " 781   -1380.381162    1.688209\n",
      " 782   -1380.400374    1.108148\n",
      " 783   -1380.426938    1.239636\n",
      " 784   -1380.442010    1.508170\n",
      " 785   -1380.470037    3.310233\n",
      " 786   -1380.509546    1.209233\n",
      " 787   -1380.525234    0.949506\n",
      " 788   -1380.544733    1.547418\n",
      " 789   -1380.561354    1.884628\n",
      " 790   -1380.584134    1.430545\n",
      " 791   -1380.611898    1.539377\n",
      " 792   -1380.628955    1.845679\n",
      " 793   -1380.642922    1.140078\n",
      " 794   -1380.662780    1.042432\n",
      " 795   -1380.675435    1.990386\n",
      " 796   -1380.692976    1.882717\n",
      " 797   -1380.706899    3.978562\n",
      " 798   -1380.740690    1.157310\n",
      " 799   -1380.748622    0.742921\n",
      " 800   -1380.771297    1.550194\n",
      " 801   -1380.779516    4.364972\n",
      " 802   -1380.808314    1.408673\n",
      " 803   -1380.821391    0.699799\n",
      " 804   -1380.828241    0.976259\n",
      " 805   -1380.846079    2.226668\n",
      " 806   -1380.869346    1.604945\n",
      " 807   -1380.889177    0.893146\n",
      " 808   -1380.913609    1.382656\n",
      " 809   -1380.928469    1.947250\n",
      " 810   -1380.941880    1.615059\n",
      " 811   -1380.961802    1.049462\n",
      " 812   -1380.974975    1.707590\n",
      " 813   -1380.985997    1.258054\n",
      " 814   -1381.005336    1.190632\n",
      " 815   -1381.020827    1.292613\n",
      " 816   -1381.035314    2.788351\n",
      " 817   -1381.053346    0.986170\n",
      " 818   -1381.059457    0.919513\n",
      " 819   -1381.074421    0.874694\n",
      " 820   -1381.089831    2.625409\n",
      " 821   -1381.105677    1.159005\n",
      " 822   -1381.116525    1.071319\n",
      " 823   -1381.126181    1.083876\n",
      " 824   -1381.135475    0.948070\n",
      " 825   -1381.148941    0.842157\n",
      " 826   -1381.158381    1.618608\n",
      " 827   -1381.173629    1.128573\n",
      " 828   -1381.188684    1.175489\n",
      " 829   -1381.199439    0.890953\n",
      " 830   -1381.201348    2.674180\n",
      " 831   -1381.220210    1.004816\n",
      " 832   -1381.227986    0.639081\n",
      " 833   -1381.237596    1.172769\n",
      " 834   -1381.245385    1.371935\n",
      " 835   -1381.246170    1.636510\n",
      " 836   -1381.263328    0.762023\n",
      " 837   -1381.268050    0.583917\n",
      " 838   -1381.270817    0.799398\n",
      " 839   -1381.281893    1.899057\n",
      " 840   -1381.294800    1.312927\n",
      " 841   -1381.303061    0.722464\n",
      " 842   -1381.313930    0.936800\n",
      " 843   -1381.322534    1.829530\n",
      " 844   -1381.333500    1.636669\n",
      " 845   -1381.350919    1.203224\n",
      " 846   -1381.360100    1.629336\n",
      " 847   -1381.366900    0.803237\n",
      " 848   -1381.374207    0.897881\n",
      " 849   -1381.380274    0.829046\n",
      " 850   -1381.386859    2.569401\n",
      " 851   -1381.396952    0.932136\n",
      " 852   -1381.402836    0.753281\n",
      " 853   -1381.410351    1.075153\n",
      " 854   -1381.417104    2.274463\n",
      " 855   -1381.426191    1.142949\n",
      " 856   -1381.438400    0.806394\n",
      " 857   -1381.445997    0.789566\n",
      " 858   -1381.450966    1.403410\n",
      " 859   -1381.464618    0.900047\n",
      " 860   -1381.473453    0.769458\n",
      " 861   -1381.484268    1.080893\n",
      " 862   -1381.488741    1.896680\n",
      " 863   -1381.501438    0.673032\n",
      " 864   -1381.505000    0.438112\n",
      "100%|████████████████████████████████████████████| 2/2 [13:44<00:00, 412.34s/it]\n"
     ]
    }
   ],
   "source": [
    "!./bin/paddlemd --conf tests/prod_alanine_dipeptide_amber/conf.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 测试结果\n",
    "飞桨  405   -1362.860203    3.397800\n",
    "torch 405   -1362.809237    10.436576\n",
    "1013   -1385.292748    2.422747"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调试\n",
    "## 执行测试之后卡住\n",
    "```\n",
    "W0503 16:17:49.902498  3748 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
    "/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py:253: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.bool, the right dtype will convert to paddle.float32\n",
    "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
    "\n",
    "Running test: test-data/thrombin-ligand-amber/\n",
    "```\n",
    "## 卡住之后，手工中断，报错信息：\n",
    "```\n",
    "Running test: test-data/thrombin-ligand-amber/\n",
    "^C\n",
    "Traceback (most recent call last):\n",
    "  File \"tests/test_paddlemd.py\", line 551, in <module>\n",
    "    unittest.main(verbosity=2)\n",
    "  File \"/opt/conda/lib/python3.6/unittest/main.py\", line 95, in __init__\n",
    "    self.runTests()\n",
    "  File \"/opt/conda/lib/python3.6/unittest/main.py\", line 256, in runTests\n",
    "    self.result = testRunner.run(self.test)\n",
    "  File \"/opt/conda/lib/python3.6/unittest/runner.py\", line 176, in run\n",
    "    test(result)\n",
    "  File \"/opt/conda/lib/python3.6/unittest/suite.py\", line 84, in __call__\n",
    "    return self.run(*args, **kwds)\n",
    "  File \"/opt/conda/lib/python3.6/unittest/suite.py\", line 122, in run\n",
    "    test(result)\n",
    "  File \"/opt/conda/lib/python3.6/unittest/suite.py\", line 84, in __call__\n",
    "    return self.run(*args, **kwds)\n",
    "  File \"/opt/conda/lib/python3.6/unittest/suite.py\", line 122, in run\n",
    "    test(result)\n",
    "  File \"/opt/conda/lib/python3.6/unittest/case.py\", line 653, in __call__\n",
    "    return self.run(*args, **kwds)\n",
    "  File \"/opt/conda/lib/python3.6/unittest/case.py\", line 605, in run\n",
    "    testMethod()\n",
    "  File \"tests/test_paddlemd.py\", line 408, in test_paddlemd\n",
    "    system.pos, system.box, system.forces, returnDetails=True\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 342, in compute\n",
    "    forces[i] = paddleindex_add(forces[i], 0, ava_idx[:, 0], -forcevec)\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 38, in paddleindex_add\n",
    "    x[index[i]] += source[i]\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 778, in __setitem__\n",
    "    return _setitem_impl_(self, item, value)\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/variable_index.py\", line 703, in _setitem_impl_\n",
    "    inplace_map={\"Input\": \"Out\"})\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 3604, in append_op\n",
    "    inplace_map)\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/tracer.py\", line 309, in trace_op\n",
    "    not stop_gradient, inplace_map if inplace_map else {})\n",
    "KeyboardInterrupt\n",
    "```\n",
    "\n",
    "## 测试水分子报错\n",
    "```\n",
    "  File \"/code/6paper/PaddleMD/bin/../paddlemd/run.py\", line 76, in setup\n",
    "    paddle.manual_seed(args.seed)\n",
    "AttributeError: module 'paddle' has no attribute 'manual_seed'\n",
    "root@f7d7b1900cfff011ec0b6ec0bb60bea6856f-task1-0:/code/6paper/PaddleMD# \n",
    "```\n",
    "问题是我看原代码，76句那句是注释掉的啊！出了灵异事件了 。\n",
    "晕，发现是改错文件了。并没有修改paddlemd那个目录的run文件，修改之。\n",
    "\n",
    "##  [operator < elementwise_add > error]\n",
    "```\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/wrapper.py\", line 19, in paddleindexjia\n",
    "    tmp[xindex] += y\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py\", line 299, in __impl__\n",
    "    return math_op(self, other_var, 'axis', axis)\n",
    "ValueError: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [3, 3] and the shape of Y = [2, 3]. Received [3] in X is not equal to [2] in Y at i:0.\n",
    "  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\n",
    "  [operator < elementwise_add > error]\n",
    "```\n",
    "这样应该是paddleeye的锅。在下面处理paddleeye\n",
    "将所有的eye相关语句，修改成这样\n",
    "```\n",
    "# box = box[:, torch.eye(3).bool()]\n",
    "box = box*paddle.eye(3)\n",
    "box = box.sum(1)\n",
    "\n",
    "同时发现在forces.py文件中，有这样一句：\n",
    "sbox = box[i][torch.eye(3).bool()]\n",
    "相关的飞桨可以写为：\n",
    "sbox = box[i][paddle.eye(3).astype(paddle.bool)]\n",
    "\n",
    "```\n",
    "脑子有点乱了，系统里面用到的eye特别多。。。\n",
    "\n",
    "6.3日，回头看这里的报错，明显是paddleindexjia的报错啊！ 因为这个函数当时写的时候维度是写死的，所以碰到新情况shpae就对不齐了。\n",
    "解决的方法是使用numpy语句解决，加上tensor的来回变换，一共4句：\n",
    "```\n",
    "#                 pos[:, group] -= offset.unsqueeze(1)\n",
    "#                 pos = paddleindexjia(pos, -offset, group)\n",
    "                pos = pos.numpy()\n",
    "                offset = offset.unsqueeze(1).numpy()\n",
    "                pos[:, group] -= offset # 尝试使用numpy来处理 相关语句共4句\n",
    "                pos = paddle.to_tensor(pos)\n",
    "\n",
    "#             pos[:, self.nongrouped] -= offset.unsqueeze(1)\n",
    "#             pos = paddleindexjia(pos, -offset, self.nongrouped)\n",
    "            pos = pos.numpy()\n",
    "            offset = offset.unsqueeze(1).numpy()\n",
    "            pos[:, self.nongrouped] -= offset # 尝试使用numpy来处理 相关语句共4句\n",
    "            pos = paddle.to_tensor(pos)\n",
    "```\n",
    "两个地方需要修改，并且第二部分应该用参数self.nongrouped，以前误写成group，这次一并改回。\n",
    "## 专门修改eye相关函数\n",
    "比如这样的，我认为可以提速：\n",
    "```\n",
    "        for r in range(box.shape[0]):\n",
    "            self.box[r][torch.eye(3).bool()] = torch.tensor(\n",
    "                box[r], dtype=self.box.dtype, device=self.box.device\n",
    "            )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理eye相关语句\n",
    "torch相关代码为`box = box[:, torch.eye(3).bool()] `\n",
    "\n",
    "## 修改paddleindex_add\n",
    "重写了paddleindex_add之后，测试水分子时报错：\n",
    "```\n",
    "[291, 3] indices.shape:[291] value.shape:[291, 3]\n",
    "==arr.shape:[291, 3] indices.shape:[291] value.shape:[291, 3]\n",
    "==arr.shape:[291, 3] indices.shape:[97] value.shape:[97, 3]\n",
    "==arr.shape:[291, 3] indices.shape:[97] value.shape:[97, 3]\n",
    "==arr.shape:[291, 3] indices.shape:[97] value.shape:[97, 3]\n",
    "==arr.shape:[291, 3] indices.shape:[15168] value.shape:[15168, 3]\n",
    "```\n",
    "不明白为什么会出来15168 这么大的值 ...\n",
    " ==arr.shape:[291, 3] indices.shape:[15168] value.shape:[15168, 3]\n",
    " \n",
    " 还有这么大的：Running test: test-data/thrombin-ligand-amber/\n",
    "==force line 276 explicit_forces:True electrostatics len of idx14[:, 0]:12320\n",
    "\n",
    "index_add里面加入截断。 要去看看torch怎么处理的，估计torch是按照顺序覆盖的。\n",
    "\n",
    "最终参考torch.index_add的实现，对paddleindex_add进行了相应修改！不截断，全部数据按照索引加上去！ \n",
    "\n",
    "\n",
    "\n",
    "## 测试报错\n",
    "```\n",
    "======================================================================\n",
    "ERROR: test_paddlemd (__main__._TestPaddleMD) (system='test-data/4dihedrals/')\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"tests/test_paddlemd.py\", line 408, in test_paddlemd\n",
    "    system.pos, system.box, system.forces, returnDetails=True\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 282, in compute\n",
    "    spos, self.par.impropers[:, 0:2], sbox\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 421, in calculate_distances\n",
    "    dist = paddle.norm(direction_vec, axis=1)\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/tensor/linalg.py\", line 436, in norm\n",
    "    name=name)\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/tensor/linalg.py\", line 308, in vector_norm\n",
    "    'keepdim', keepdim, 'asvector', asvector)\n",
    "ValueError: (InvalidArgument) Attr(axis) value should be in range [-R, R-1], R is the rank of Input(X). But received axis: 1, R: 1. Current Input(X)'s shape is=[3].\n",
    "  [Hint: Expected axis < x_rank, but received axis:1 >= x_rank:1.] (at /paddle/paddle/phi/infermeta/unary.cc:1488)\n",
    "  [operator < p_norm > error]\n",
    "```\n",
    " value should be in range [-R, R-1], R is the rank of Input(X). But received axis: 1, R: 1. Current Input(X)'s shape is=[3].\n",
    "\n",
    "还是函数里面没弄好导致的，全部逻辑理顺，终于顺利测试完成了。（调哪个函数？ 为什么6.5日又出现了这个报错？ ）\n",
    "\n",
    " \n",
    " ## 测试的时候报错没有openmm\n",
    " 发现pip安装的openmm不行，要用canda安装\n",
    "需要使用`conda install openmm -c conda-forge`\n",
    "且安装的时候会安装cuda\n",
    "\n",
    "## 在测试时，发现很多时候没有用到paddle.norm部分，用的地方报错\n",
    "```python\n",
    "Traceback (most recent call last):\n",
    "  File \"tests/test_paddlemd.py\", line 408, in test_paddlemd\n",
    "    system.pos, system.box, system.forces, returnDetails=True\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 201, in compute\n",
    "    spos, self.par.dihedrals[:, 0:2], sbox\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 422, in calculate_distances\n",
    "    dist = paddle.norm(direction_vec, axis=1)\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/tensor/linalg.py\", line 436, in norm\n",
    "    name=name)\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/tensor/linalg.py\", line 308, in vector_norm\n",
    "    'keepdim', keepdim, 'asvector', asvector)\n",
    "ValueError: (InvalidArgument) Attr(axis) value should be in range [-R, R-1], R is the rank of Input(X). But received axis: 1, R: 1. Current Input(X)'s shape is=[3].\n",
    "  [Hint: Expected axis < x_rank, but received axis:1 >= x_rank:1.] (at /paddle/paddle/phi/infermeta/unary.cc:1488)\n",
    "  [operator < p_norm > error]\n",
    "重点检查：  \n",
    "def calculate_distances(atom_pos, atom_idx, box):\n",
    "#     print(f\"==calculate_distances {atom_pos, atom_idx, box}\")\n",
    "#     print(f\"==calculate_distances atom_pos, atom_idx, box:{atom_pos.shape, atom_idx.shape, box.shape}\")\n",
    "\n",
    "    direction_vec = wrap_dist(atom_pos[atom_idx[:, 0]] - atom_pos[atom_idx[:, 1]], box)\n",
    "    print(f\"==line 423 of forces direction_vec.shape:{direction_vec.shape}\")\n",
    "    dist = paddle.norm(direction_vec, axis=1)\n",
    "    direction_unitvec = direction_vec / dist.unsqueeze(1)\n",
    "    return dist, direction_unitvec, direction_vec\n",
    "```\n",
    "\n",
    "## 集中全力处理test_replicas, Attr(axis) value should be in range [-R, R-1]\n",
    "```python\n",
    "test_replicas (__main__._TestPaddleMD) ... ERROR\n",
    "\n",
    "======================================================================\n",
    "ERROR: test_paddlemd (__main__._TestPaddleMD) (system='test-data/4dihedrals/')\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"tests/test_paddlemd.py\", line 408, in test_paddlemd\n",
    "    system.pos, system.box, system.forces, returnDetails=True\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 284, in compute\n",
    "    _, _, r12 = calculate_distances(\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 424, in calculate_distances\n",
    "    #     print(f\"==line 423 of forces direction_vec.shape:{direction_vec.shape}\")\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/tensor/linalg.py\", line 436, in norm\n",
    "    name=name)\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/tensor/linalg.py\", line 308, in vector_norm\n",
    "    'keepdim', keepdim, 'asvector', asvector)\n",
    "ValueError: (InvalidArgument) Attr(axis) value should be in range [-R, R-1], R is the rank of Input(X). But received axis: 1, R: 1. Current Input(X)'s shape is=[3].\n",
    "  [Hint: Expected axis < x_rank, but received axis:1 >= x_rank:1.] (at /paddle/paddle/phi/infermeta/unary.cc:1488)\n",
    "  [operator < p_norm > error]\n",
    "```\n",
    "## 先集中精力处理'Tensor' object has no attribute 'requires_grad'\n",
    "```\n",
    "======================================================================\n",
    "ERROR: test_replicas (__main__._TestPaddleMD)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"tests/test_paddlemd.py\", line 517, in test_replicas\n",
    "    explicit_forces=False,\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 386, in compute\n",
    "    if pot[i][ene].requires_grad:\n",
    "AttributeError: 'Tensor' object has no attribute 'requires_grad'\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 423.041s\n",
    "\n",
    "FAILED (errors=7)\n",
    "```\n",
    "将requires_grad改成stop_gradient ，当然飞桨的语法是xx.stop_gradient=False\n",
    "问题解决之后，出现新的报错\n",
    "##   (PermissionDenied) Cannot set target var auto_1600864_@GRAD twice\n",
    "说实话，这是我印象里头一次碰到这样的报错\n",
    "```\n",
    "======================================================================\n",
    "ERROR: test_replicas (__main__._TestPaddleMD)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"tests/test_paddlemd.py\", line 517, in test_replicas\n",
    "    explicit_forces=False,\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 390, in compute\n",
    "    enesum, pos, only_inputs=True, retain_graph=True\n",
    "  File \"</opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-49>\", line 2, in grad\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\n",
    "    return wrapped_func(*args, **kwargs)\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/framework.py\", line 434, in __impl__\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/base.py\", line 663, in grad\n",
    "    retain_graph, allow_unused, only_inputs)\n",
    "RuntimeError: (PermissionDenied) Cannot set target var auto_1600864_@GRAD twice\n",
    "  [Hint: Expected ready_var.var == nullptr, but received ready_var.var != nullptr.] (at /paddle/paddle/fluid/imperative/partial_grad_engine.cc:508)\n",
    "```\n",
    "经了解，paddle.grad可能有些问题，不过我认为大概率还是自己的问题。 \n",
    "这个报错，是说不能设置变量两次？ \n",
    "\n",
    "## 测试前丙氨酸二肽报错\n",
    "```python\n",
    "  File \"/code/6paper/PaddleMD/bin/../paddlemd/run.py\", line 154, in <module>\n",
    "    mol, system, forces = setup(args)\n",
    "  File \"/code/6paper/PaddleMD/bin/../paddlemd/run.py\", line 113, in setup\n",
    "    forces = Forces(parameters, terms=args.forceterms, external=external, cutoff=args.cutoff, rfa=args.rfa, switch_dist=args.switch_dist, exclusions=args.exclusions)\n",
    "  File \"/code/6paper/PaddleMD/paddlemd/forces.py\", line 103, in __init__\n",
    "    'Set force terms or leave empty brackets [].\\nAvailable options: \"bonds\", \"angles\", \"dihedrals\", \"impropers\", \"1-4\", \"electrostatics\", \"lj\", \"repulsion\", \"repulsioncg\".'\n",
    "RuntimeError: Set force terms or leave empty brackets [].\n",
    "Available options: \"bonds\", \"angles\", \"dihedrals\", \"impropers\", \"1-4\", \"electrostatics\", \"lj\", \"repulsion\", \"repulsioncg\".\n",
    "```    \n",
    "把forces.py文件中修改成：\n",
    "```\n",
    "if terms is None: # 为了不报错，我也是拼了\n",
    "            terms = self.terms\n",
    "```\n",
    "终于可以跑下去了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3567,  0.9546, -0.2460],\n",
      "        [ 0.1134,  0.3881, -0.4628]], dtype=torch.float64)\n",
      "[-0.35666844  0.95460963 -0.24597028]\n",
      "[[-0.35666844  0.95460963 -0.24597028]\n",
      " [ 0.11340753  0.38805964 -0.46283856]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.randn(2,3,3)\n",
    "\n",
    "# print(a)\n",
    "import torch\n",
    "ta = torch.tensor(a)\n",
    "# print(ta)\n",
    "ta = ta[:, torch.eye(3).bool()]\n",
    "print(ta)\n",
    "box = a\n",
    "i = 0\n",
    "sbox = box[i][torch.eye(3).bool()]\n",
    "print(sbox)\n",
    "sbox = box[:, torch.eye(3).bool()]\n",
    "print(sbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[2, 3], dtype=float64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[ 0.78369857, -1.16356505,  0.76762212],\n",
      "        [ 1.44171350, -0.14697054,  0.07857292]])\n",
      "Tensor(shape=[3], dtype=float64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [ 0.78369857, -1.16356505,  0.76762212])\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "box = paddle.to_tensor(a)\n",
    "box = box*paddle.eye(3)\n",
    "box = box.sum(1)\n",
    "print(box)\n",
    "box = paddle.to_tensor(a)\n",
    "sbox = box[i][paddle.eye(3).astype(paddle.bool)]\n",
    "print(sbox)\n",
    "# box[:][paddle.eye(3).astype(paddle.bool)]\n",
    "# print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[2, 3], dtype=float64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[ 0.78369857, -1.16356505,  0.76762212],\n",
      "        [ 1.44171350, -0.14697054,  0.07857292]])\n"
     ]
    }
   ],
   "source": [
    "# box = box[:, torch.eye(3).bool()]\n",
    "box = box*paddle.eye(3)\n",
    "box = box.sum(1)\n",
    "print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "(InvalidArgument) Currently, Tensor.__indices__() only allows indexing by Integers, Slices, Ellipsis, None, tuples of these types and list of Bool and Integers, but received Tensor in 1th slice item (at /paddle/paddle/fluid/pybind/slice_utils.h:279)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-44eef7e961a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;31m# 2. Call c++ func getitem_index_not_tensor to speedup.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_index_not_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: (InvalidArgument) Currently, Tensor.__indices__() only allows indexing by Integers, Slices, Ellipsis, None, tuples of these types and list of Bool and Integers, but received Tensor in 1th slice item (at /paddle/paddle/fluid/pybind/slice_utils.h:279)\n"
     ]
    }
   ],
   "source": [
    "sbox = box[i][torch.eye(3).bool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-a52227f72273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     selfbox[r][torch.eye(3).bool()] = torch.tensor(\n\u001b[0;32m----> 5\u001b[0;31m         box[r], dtype=selfbox.dtype)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselfbox\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "selfbox = ta\n",
    "box = a\n",
    "for r in range(box.shape[0]):\n",
    "    selfbox[r][torch.eye(3).bool()] = torch.tensor(\n",
    "        box[r], dtype=selfbox.dtype)\n",
    "print(selfbox )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8ce042bf456a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m selfbox[0][torch.eye(3).bool()] = torch.tensor(\n\u001b[0;32m----> 2\u001b[0;31m         box[0], dtype=selfbox.dtype)\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "selfbox[0][torch.eye(3).bool()] = torch.tensor(\n",
    "        box[0], dtype=selfbox.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[2, 3, 3], dtype=float64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[-0.35666844,  0.        ,  0.        ],\n",
      "         [ 0.        ,  0.95460963,  0.        ],\n",
      "         [ 0.        ,  0.        , -0.24597028]],\n",
      "\n",
      "        [[ 0.11340753,  0.        ,  0.        ],\n",
      "         [ 0.        ,  0.38805964,  0.        ],\n",
      "         [ 0.        ,  0.        , -0.46283856]]])\n"
     ]
    }
   ],
   "source": [
    "selfbox = paddle.to_tensor(a)\n",
    "for r in range(box.shape[0]):\n",
    "#             self.box[r][paddle.eye(3).astype(paddle.bool)] = paddle.to_tensor(\n",
    "#                 box[r], dtype=self.box.dtype)\n",
    "    selfbox[r] = paddle.to_tensor(\n",
    "        box[r], dtype=selfbox.dtype) * paddle.eye(3).astype(paddle.bool)\n",
    "print(selfbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "(InvalidArgument) fill_constant(): argument (position 6) must be float, but got numpy.ndarray (at /paddle/paddle/fluid/pybind/op_function_common.cc:189)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8a8e62bfd501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(self, other_var)\u001b[0m\n\u001b[1;32m    256\u001b[0m                         \u001b[0;31m# add fill_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                         other_var = create_scalar(\n\u001b[0;32m--> 258\u001b[0;31m                             value=other_var, dtype=lhs_dtype)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;31m# 3. promote types or unify right var type to left var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py\u001b[0m in \u001b[0;36mcreate_scalar\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-278>\u001b[0m in \u001b[0;36mcreate_tensor\u001b[0;34m(value, dtype, shape)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/base.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_switch_tracer_mode_guard_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py\u001b[0m in \u001b[0;36mcreate_tensor\u001b[0;34m(value, dtype, shape)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_varbase_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         out = _C_ops.fill_constant(out, 'dtype', dtype, 'shape', shape, 'value',\n\u001b[0;32m---> 85\u001b[0;31m                                    value, 'force_cpu', False)\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: (InvalidArgument) fill_constant(): argument (position 6) must be float, but got numpy.ndarray (at /paddle/paddle/fluid/pybind/op_function_common.cc:189)\n"
     ]
    }
   ],
   "source": [
    "# tmp = box*paddle.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 飞桨grad例子\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1, 2], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[1., 1.]])\n",
      "==dx:Tensor(shape=[1, 2], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[2., 2.]])\n",
      "[[2. 2.]]\n",
      "Tensor(shape=[1, 2], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[1., 1.]])\n",
      "==dx:Tensor(shape=[1, 2], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[2., 2.]])\n",
      "[[4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "def test_dygraph_grad(create_graph):\n",
    "    x = paddle.ones(shape=[1,2], dtype='float32')\n",
    "    x.stop_gradient = False\n",
    "    y = x * x\n",
    "    print(y)\n",
    "\n",
    "    # Since y = x * x, dx = 2 * x\n",
    "    dx = paddle.grad(\n",
    "            outputs=[y],\n",
    "            inputs=[x],\n",
    "            create_graph=create_graph,\n",
    "            retain_graph=True)[0]\n",
    "    print(f\"==dx:{dx}\")\n",
    "    z = y + dx\n",
    "\n",
    "    # If create_graph = False, the gradient of dx\n",
    "    # would not be backpropagated. Therefore,\n",
    "    # z = x * x + dx, and x.gradient() = 2 * x = 2.0\n",
    "\n",
    "    # If create_graph = True, the gradient of dx\n",
    "    # would be backpropagated. Therefore,\n",
    "    # z = x * x + dx = x * x + 2 * x, and\n",
    "    # x.gradient() = 2 * x + 2 = 4.0\n",
    "\n",
    "    z.backward()\n",
    "    return x.gradient()\n",
    "\n",
    "print(test_dygraph_grad(create_graph=False)) # [2.]\n",
    "print(test_dygraph_grad(create_graph=True)) # [4.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.]\n",
      "[16.]\n",
      "[19.]\n",
      "[24.]\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "def test_dygraph_grad(grad_outputs=None):\n",
    "    x = paddle.to_tensor(2.0)\n",
    "    x.stop_gradient = False\n",
    "\n",
    "    y1 = x * x\n",
    "    y2 = x * 3\n",
    "\n",
    "    # If grad_outputs=None, dy1 = [1], dy2 = [1].\n",
    "    # If grad_outputs=[g1, g2], then:\n",
    "    #    - dy1 = [1] if g1 is None else g1\n",
    "    #    - dy2 = [1] if g2 is None else g2\n",
    "\n",
    "    # Since y1 = x * x, dx = 2 * x * dy1.\n",
    "    # Since y2 = x * 3, dx = 3 * dy2.\n",
    "    # Therefore, the final result would be:\n",
    "    # dx = 2 * x * dy1 + 3 * dy2 = 4 * dy1 + 3 * dy2.\n",
    "\n",
    "    dx = paddle.grad(\n",
    "        outputs=[y1, y2],\n",
    "        inputs=[x],\n",
    "        grad_outputs=grad_outputs)[0]\n",
    "\n",
    "    return dx.numpy()\n",
    "\n",
    "grad_value = paddle.to_tensor(4.0)\n",
    "\n",
    "# dy1 = [1], dy2 = [1]\n",
    "print(test_dygraph_grad(None)) # [7.]\n",
    "\n",
    "# dy1 = [1], dy2 = [4]\n",
    "print(test_dygraph_grad([None, grad_value])) # [16.]\n",
    "\n",
    "# dy1 = [4], dy2 = [1]\n",
    "print(test_dygraph_grad([grad_value, None])) # [19.]\n",
    "\n",
    "# dy1 = [3], dy2 = [4]\n",
    "grad_y1 = paddle.to_tensor(3.0)\n",
    "print(test_dygraph_grad([grad_y1, grad_value])) # [24.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms:None\n",
      "terms:['bonds', 'angles', 'dihedrals', 'impropers', '1-4', 'electrostatics', 'lj', 'repulsion', 'repulsioncg']\n"
     ]
    }
   ],
   "source": [
    "class Forces:\n",
    "    # 1-4 is nonbonded but we put it currently in bonded to not calculate all distances\n",
    "    bonded = [\"bonds\", \"angles\", \"dihedrals\", \"impropers\", \"1-4\"]\n",
    "    nonbonded = [\"electrostatics\", \"lj\", \"repulsion\", \"repulsioncg\"]\n",
    "    terms = bonded + nonbonded\n",
    "    def __init__(\n",
    "        self,\n",
    "        terms=None):\n",
    "        print(f\"terms:{terms}\")\n",
    "        if terms is None:\n",
    "            terms = self.terms\n",
    "        print(f\"terms:{terms}\")\n",
    "test = Forces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
