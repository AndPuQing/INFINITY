{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 飞桨提速\n",
    "针对飞桨速度慢的问题，对比常见的函数，发现瓶颈代码，修改以提升运行速度\n",
    "\n",
    "所有的函数运行测试。\n",
    "发现只要带上for循环的，速度就要慢很多，大约30倍左右。\n",
    "2022.5.12 今天把速度提升了10倍，离torch还差20倍左右。但是2号文件提速成功，1号文件提速没有成功，还没找到代码差异在哪里。 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class Timer:  #@save\n",
    "    \"\"\"记录多次运行时间\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "\n",
    "class Benchmark:\n",
    "    \"\"\"用于测量运行时间\"\"\"\n",
    "    def __init__(self, description='Done'):\n",
    "        self.description = description\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.timer = Timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        print(f'{self.description}: {self.timer.stop():.4f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import torch\n",
    "import time\n",
    "import time\n",
    "class Timer:  #@save\n",
    "    \"\"\"记录多次运行时间\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "\n",
    "class Benchmark:\n",
    "    \"\"\"用于测量运行时间\"\"\"\n",
    "    def __init__(self, description='Done'):\n",
    "        self.description = description\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.timer = Timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        print(f'{self.description}: {self.timer.stop():.4f} sec')\n",
    "\n",
    "def paddlerandn_like(x) : # 添加飞桨的randn_like函数\n",
    "    '''输出x维度的随机tensor'''\n",
    "    return paddle.randn(x.shape)\n",
    "\n",
    "from math import pi\n",
    "# 发现飞桨支持atan2函数，且自己写的只适合1D数据\n",
    "# def paddleatan2(input, other): # 飞桨的atan2函数\n",
    "#     atan = paddle.atan(input/other)\n",
    "#     atan[1] = atan[1] + pi\n",
    "#     atan[2] = atan[2] + pi\n",
    "#     return atan\n",
    "\n",
    "def paddlescatter(x, dim, index, src): # scatter支持1D版本\n",
    "    \n",
    "    updates = src\n",
    "    if len(index.shape) == 1 :\n",
    "#         for i in index:\n",
    "#             x[i] += updates[i]\n",
    "        \n",
    "        for i in range(index.shape[0]):\n",
    "            x[index[i]] += updates[i]\n",
    "        \n",
    "        return x\n",
    "                                \n",
    "    i, j = index.shape\n",
    "    grid_x , grid_y = paddle.meshgrid(paddle.arange(i), paddle.arange(j))\n",
    "    if dim == 0 :\n",
    "        index = paddle.stack([index.flatten(), grid_y.flatten()], axis=1)\n",
    "    elif dim == 1:\n",
    "        index = paddle.stack([grid_x.flatten(), index.flatten()], axis=1)\n",
    "        \n",
    "    # PaddlePaddle updates 的 shape 大小必须与 index 对应\n",
    "    updates_index = paddle.stack([grid_x.flatten(), grid_y.flatten()], axis=1)\n",
    "    updates = paddle.gather_nd(updates, index=updates_index)\n",
    "    return paddle.scatter_nd_add(x, index, updates)\n",
    "\n",
    "def paddleindex_add(x, dim, index, source): # 飞桨的index_add\n",
    "    '''\n",
    "x = paddle.ones([5, 3])\n",
    "t = paddle.to_tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=paddle.float32)\n",
    "index = paddle.to_tensor([0, 4, 2])\n",
    "# print(x)\n",
    "with Benchmark(\"paddleindex_add\"):\n",
    "    x = paddleindex_add(x, 0, index, t)\n",
    "print(x)\n",
    "    '''\n",
    "    for i in range(len(index)):\n",
    "        x[index[i]] += source[i]\n",
    "    return x\n",
    "\n",
    "def paddleeye(x, n): # 针对[1, 3, 3]输入的特供eye函数\n",
    "    tmp =x[0][paddle.eye(n).astype(paddle.bool)]\n",
    "    return tmp.unsqueeze_(0)\n",
    "\n",
    "def paddleindexjia (x, y, xindex): # 索引/切片/赋值特供版本\n",
    "    '''\n",
    "    切片+索引，使用循环来解决切片问题，然后使用中间变量，来实现按照索引赋值\n",
    "    支持类似的语句pos[:, group] -= offset.unsqueeze(1)\n",
    "    '''\n",
    "    xlen = len(x)\n",
    "    assert len(x.shape) == 3 , \"维度不一致,必须为3D数据\"\n",
    "#     if len(y.shape) == 3 and y.shape[0] ==1 :\n",
    "#         y = paddle.squeeze(y)\n",
    "    assert len(y.shape) ==2 , \"维度不一致，必须为2D数据\"\n",
    "    for i in range(xlen):\n",
    "        tmp = x[i]\n",
    "        tmp[xindex] += y\n",
    "        x[i] = tmp\n",
    "    return x\n",
    "\n",
    "# 写飞桨版本的笛卡尔直积函数cartesian_prod\n",
    "from itertools import product\n",
    "def paddlecartesian_prod(x,y): # 飞桨版本的笛卡尔直积函数\n",
    "    z = list(product(x,y))\n",
    "    z = paddle.to_tensor(z)\n",
    "    return z.squeeze(axis=-1)\n",
    "\n",
    "def paddlecartesian_prod(arrays, out=None): # 飞桨版本的笛卡尔直积函数cartesian_prod\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    # print(arrays)\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    #m = n / arrays[0].size\n",
    "    m = int(n / arrays[0].size) \n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m, 1:])\n",
    "    for j in range(1, arrays[0].size):\n",
    "    #for j in xrange(1, arrays[0].size):\n",
    "        out[j*m:(j+1)*m, 1:] = out[0:m, 1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.randn_like: 0.0004 sec\n",
      "paddlerandn_like: 1.7966 sec\n",
      "torch.randn_like: 0.0014 sec\n",
      "tensor([[ 0.5133,  2.0725,  1.8930],\n",
      "        [ 0.2994,  0.9608, -0.3013],\n",
      "        [ 0.0311, -0.1051, -0.0998]]) torch.Size([3, 3]) Tensor(shape=[3, 3], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[ 0.26284698,  0.12275082, -0.17302011],\n",
      "        [-1.07301319,  0.66473138, -1.46612263],\n",
      "        [-1.39956117, -0.31305528,  1.45490885]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import paddle\n",
    "import numpy as np \n",
    "\n",
    "npa = np.ndarray([3,3])\n",
    "ta = torch.Tensor(npa)\n",
    "pa = paddle.to_tensor(npa)\n",
    "with Benchmark(\"torch.randn_like\"):\n",
    "    ta = torch.randn_like(ta)\n",
    "#     torch.cuda.synchronize\n",
    "with Benchmark(\"paddlerandn_like\"):\n",
    "    pa = paddlerandn_like(pa)\n",
    "with Benchmark(\"torch.randn_like\"):\n",
    "    ta = torch.randn_like(ta)\n",
    "print(ta,ta.shape, pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0714, -0.8288,  1.4877, -0.8761])\n",
      "tensor([ 1.0714,  2.3127, -1.6539, -0.8761])\n",
      "torch.atan2 time: 0.0002 sec\n",
      "tensor([ 1.0714,  2.3127, -1.6539, -0.8761])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "pi = math.pi\n",
    "real = torch.tensor([ 0.12,  -1.1, -0.1, 1])\n",
    "imag = torch.tensor([ 0.22,  1.2, -1.2, -1.2])\n",
    "atan = torch.atan(imag/real)\n",
    "print(atan)\n",
    "atan[1] = atan[1] + pi\n",
    "atan[2] = atan[2] - pi\n",
    "print(atan)\n",
    "with Benchmark(\"torch.atan2 time\"):\n",
    "    atan2 = torch.atan2(imag,real)\n",
    "print(atan2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [ 1.07144964, -0.82884914,  1.48765516, -0.87605810])\n",
      "Tensor(shape=[4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [ 1.07144964,  2.31274366, -1.65393758, -0.87605810])\n",
      "Tensor(shape=[4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [ 1.07144964,  2.31274366,  4.62924767, -0.87605810])\n",
      "paddleatan2 time: 0.0011 sec\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import math\n",
    "\n",
    "pi = math.pi\n",
    "real = paddle.to_tensor([ 0.12,  -1.1, -0.1, 1])\n",
    "imag = paddle.to_tensor([ 0.22,  1.2, -1.2, -1.2])\n",
    "atan = paddle.atan(imag/real)\n",
    "print(atan)\n",
    "atan[1] = atan[1] + pi\n",
    "atan[2] = atan[2] - pi\n",
    "print(atan)\n",
    "# atan2 = torch.atan2(imag,real)\n",
    "# print(atan2)\n",
    "\n",
    "import paddle\n",
    "import math\n",
    "def paddleatan2(input, other):\n",
    "    atan = paddle.atan(input/other)\n",
    "    atan[1] = atan[1] + pi\n",
    "    atan[2] = atan[2] + pi\n",
    "    return atan\n",
    "with Benchmark(\"paddleatan2 time\"):\n",
    "    print(paddleatan2(imag, real ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle.atan2 time: 0.0002 sec\n"
     ]
    }
   ],
   "source": [
    "with Benchmark(\"paddle.atan2 time\"):\n",
    "    paddle.atan2(imag,real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle.atan2 time: 0.0001 sec\n"
     ]
    }
   ],
   "source": [
    "x = paddle.randn([2, 3, 3])\n",
    "y = paddle.randn([2, 3, 4])\n",
    "with Benchmark(\"paddle.atan2 time\"):\n",
    "    paddle.atan2(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[3, 5], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[1, 2, 3, 0, 0],\n",
      "        [6, 7, 0, 0, 8],\n",
      "        [0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 测试paddlescatter\n",
    "# pot = paddlescatter(x=pot, dim=0, index=idx, src=k0 * (1 + paddle.cos(angleDiff))) # x, dim, index, src\n",
    "x = paddle.zeros([3, 5], dtype=\"int64\")\n",
    "updates = paddle.arange(1, 11).reshape([2,5])\n",
    "# 输出\n",
    "# Tensor(shape=[2, 5], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
    "#        [[1 , 2 , 3 , 4 , 5 ],\n",
    "#         [6 , 7 , 8 , 9 , 10]])\n",
    "index = paddle.to_tensor([[0, 1, 2], [0, 1, 4]])\n",
    "\n",
    "tmp = paddlescatter(x=x, dim=1, index=index, src=updates)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "paddlescatter: 0.0081 sec\n",
      "Tensor(shape=[10], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [10, 5 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ])\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "src = paddle.ones([5])\n",
    "src = paddle.to_tensor([1, 2, 3, 4, 5])\n",
    "index = paddle.to_tensor([0, 2, 0, 1, 4])\n",
    "index = paddle.to_tensor([0, 0, 0, 0, 1])\n",
    "print(index.shape)\n",
    "tmp = paddle.zeros([10], dtype=src.dtype)\n",
    "with Benchmark(\"paddlescatter\"):\n",
    "    tmp = paddlescatter(tmp, 0, index, src)\n",
    "# tmp = paddle.scatter(tmp, index, src)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.scatter_add_: 0.0004 sec\n",
      "tensor([10,  5,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "torch.scatter_add: 0.0003 sec\n",
      "tensor([10,  5,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "src = torch.ones([5])\n",
    "src = torch.tensor([1, 2, 3, 4, 5])\n",
    "# index = torch.tensor([0, 1, 2, 0, 0])\n",
    "index = torch.tensor([0, 2, 0, 1, 4])\n",
    "index = torch.tensor([0, 0, 0, 0, 1])\n",
    "print(index.shape)\n",
    "with Benchmark(\"torch.scatter_add_\"):\n",
    "    tmp = torch.zeros(10, dtype=src.dtype).scatter_add_(0, index, src)\n",
    "print(tmp)\n",
    "with Benchmark(\"torch.scatter_add\"):\n",
    "    tmp = torch.scatter_add(torch.zeros(10, dtype=src.dtype), 0, index, src)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.index_add_: 0.0001 sec\n",
      "tensor([[ 2.,  3.,  4.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 8.,  9., 10.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 5.,  6.,  7.]])\n",
      "paddleindex_add: 0.0057 sec\n",
      "Tensor(shape=[5, 3], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[2. , 3. , 4. ],\n",
      "        [1. , 1. , 1. ],\n",
      "        [8. , 9. , 10.],\n",
      "        [1. , 1. , 1. ],\n",
      "        [5. , 6. , 7. ]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, 3)\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
    "index = torch.tensor([0, 4, 2])\n",
    "print(len(index))\n",
    "print(x)\n",
    "with Benchmark(\"torch.index_add_\"):\n",
    "    x.index_add_(0, index, t)\n",
    "print(x)\n",
    "# x.index_add_(0, index, t, alpha=-1)\n",
    "\n",
    "x = paddle.ones([5, 3])\n",
    "t = paddle.to_tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=paddle.float32)\n",
    "index = paddle.to_tensor([0, 4, 2])\n",
    "# print(len(index))\n",
    "# print(x)\n",
    "with Benchmark(\"paddleindex_add\"):\n",
    "    x = paddleindex_add(x, 0, index, t)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "torch.index_add_: 0.0002 sec\n",
      "tensor([[ 2.,  1.,  4.,  1.,  3.],\n",
      "        [ 5.,  1.,  7.,  1.,  6.],\n",
      "        [ 8.,  1., 10.,  1.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(3, 5)\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
    "index = torch.tensor([0, 4, 2])\n",
    "print(len(index))\n",
    "print(x)\n",
    "with Benchmark(\"torch.index_add_\"):\n",
    "    x.index_add_(1, index, t)\n",
    "print(x)\n",
    "# x.index_add_(0, index, t, alpha=-1)print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(688, 3)\n",
    "# t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
    "t = torch.randn(687, 3)\n",
    "# index = torch.tensor([0, 4, 2])\n",
    "index = torch.randn(687).type(torch.int64)+5\n",
    "print(index[:10])\n",
    "index = torch.Tensor(np.arange(687)).type(torch.int64)\n",
    "\n",
    "x.index_add_(0, index, t)\n",
    "\n",
    "x = torch.ones(688,3)\n",
    "t = torch.randn\n",
    "# x.index_add_?\n",
    "# x.index_add_(0, index, t, alpha=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddleindex_add: 0.0000 sec\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`indices` and `arr` must have the same number of dimensions!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f396219db4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mBenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"paddleindex_add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# [[99, 99, 99],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/paddle/tensor/manipulation.py\u001b[0m in \u001b[0;36mput_along_axis\u001b[0;34m(arr, indices, values, axis, reduce)\u001b[0m\n\u001b[1;32m   2915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m         raise ValueError(\n\u001b[0;32m-> 2917\u001b[0;31m             \"`indices` and `arr` must have the same number of dimensions!\")\n\u001b[0m\u001b[1;32m   2918\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_negative_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m     \u001b[0mbroadcast_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `indices` and `arr` must have the same number of dimensions!"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "# x = paddle.to_tensor([[10, 30, 20], [60, 40, 50]])\n",
    "# index = paddle.to_tensor([[0]])\n",
    "# value = 99\n",
    "# value = paddle.to_tensor([100,100,200])\n",
    "# axis = 0\n",
    "# result = paddle.put_along_axis(x, index, value, axis, reduce=\"add\")\n",
    "# print(result)\n",
    "\n",
    "x = paddle.ones([688, 3])\n",
    "# value = paddle.to_tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=paddle.float32)\n",
    "value = paddle.randn([688, 3])\n",
    "# index = paddle.randn([687]).astype(paddle.int64) +5\n",
    "index = paddle.to_tensor(np.arange(687), paddle.int64)\n",
    "# index = paddle.to_tensor([0, 4, 2])\n",
    "axis = 0\n",
    "# print(len(index))\n",
    "# print(x)\n",
    "with Benchmark(\"paddleindex_add\"):\n",
    "    x = paddle.put_along_axis(x, index, value, axis, reduce=\"add\")\n",
    "print(x.shape)\n",
    "# [[99, 99, 99],\n",
    "# [60, 40, 50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box[:, torch.eye(3).bool()]: 0.0005 sec\n",
      "tensor([[1., 1., 1.]]) torch.Size([1, 3])\n",
      "paddleeye(x,3): 0.0007 sec\n",
      "Tensor(shape=[1, 3], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# torch eye 看看\n",
    "import torch \n",
    "box = torch.ones([1, 3, 3])\n",
    "# box = box +box\n",
    "with Benchmark(\"box[:, torch.eye(3).bool()]\"):\n",
    "    box = box[:, torch.eye(3).bool()]\n",
    "# box = box[:][torch.eye(3).bool()]\n",
    "print(box, box.shape)\n",
    "import paddle\n",
    "x = paddle.ones([1, 3, 3])\n",
    "with Benchmark(\"paddleeye(x,3)\"):\n",
    "    tmp = paddleeye(x,3)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3])\n",
      "torch x[:, xindex] -= uy: 0.0004 sec\n",
      "torch.Size([1, 4, 3]) tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [1., 1., 1.]]])\n",
      "paddle uy shape:[3]\n",
      "paddleindexjia: 0.0040 sec\n",
      "Tensor(shape=[1, 4, 3], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [1., 1., 1.]]])\n",
      "torch x[:, xindex] -= uy: 0.0001 sec\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones([1,4,3])\n",
    "xindex = [0,1,2]\n",
    "y = torch.ones([1,3])\n",
    "uy = y.unsqueeze(1)\n",
    "print(uy.shape)\n",
    "# uy = paddle.squeeze(y)\n",
    "# tmp = paddleindexjia (x, uy, xindex)\n",
    "# tmp = paddleindexjia(x, paddle.squeeze(y), xindex)\n",
    "# x[:, xindex] -= y.unsqueeze(1)\n",
    "with Benchmark(\"torch x[:, xindex] -= uy\"):\n",
    "    x[:, xindex] -= uy\n",
    "print(x.shape, x)\n",
    "\n",
    "x = paddle.ones([1,4,3])\n",
    "xindex = [0,1,2]\n",
    "y = paddle.ones([1,3])\n",
    "uy = paddle.squeeze(y)\n",
    "print(f\"paddle uy shape:{uy.shape}\")\n",
    "# tmp = paddleindexjia (x, uy, xindex)\n",
    "with Benchmark(\"paddleindexjia\"):\n",
    "    tmp = paddleindexjia(x, -y, xindex)\n",
    "print(tmp)\n",
    "y.numpy()\n",
    "import numpy as np\n",
    "nx = np.ndarray([1, 4, 3])\n",
    "xindex = [0, 1, 2]\n",
    "y = torch.ones([1,3])\n",
    "uy = y.unsqueeze(1)\n",
    "uy = uy.numpy()\n",
    "x = paddle.ones([1,4,3])\n",
    "nx = x.numpy()\n",
    "with Benchmark(\"numpy x[:, xindex] -= uy\"):\n",
    "    nx[:, xindex] -= uy\n",
    "print(nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 笛卡尔积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    # print(arrays)\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    #m = n / arrays[0].size\n",
    "    m = int(n / arrays[0].size) \n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m, 1:])\n",
    "    for j in range(1, arrays[0].size):\n",
    "    #for j in xrange(1, arrays[0].size):\n",
    "        out[j*m:(j+1)*m, 1:] = out[0:m, 1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddleindexjia: 0.0002 sec\n"
     ]
    }
   ],
   "source": [
    "cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "r = [-1, 0, 1]\n",
    "r = paddle.to_tensor(r)\n",
    "with Benchmark(\"paddleindexjia\"):\n",
    "    cartesian([r, r, r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1.],\n",
      "        [-1., -1.,  0.],\n",
      "        [-1., -1.,  1.],\n",
      "        [-1.,  0., -1.],\n",
      "        [-1.,  0.,  0.],\n",
      "        [-1.,  0.,  1.],\n",
      "        [-1.,  1., -1.],\n",
      "        [-1.,  1.,  0.],\n",
      "        [-1.,  1.,  1.],\n",
      "        [ 0., -1., -1.],\n",
      "        [ 0., -1.,  0.],\n",
      "        [ 0., -1.,  1.],\n",
      "        [ 0.,  0., -1.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.],\n",
      "        [ 0.,  1., -1.],\n",
      "        [ 0.,  1.,  0.],\n",
      "        [ 0.,  1.,  1.],\n",
      "        [ 1., -1., -1.],\n",
      "        [ 1., -1.,  0.],\n",
      "        [ 1., -1.,  1.],\n",
      "        [ 1.,  0., -1.],\n",
      "        [ 1.,  0.,  0.],\n",
      "        [ 1.,  0.,  1.],\n",
      "        [ 1.,  1., -1.],\n",
      "        [ 1.,  1.,  0.],\n",
      "        [ 1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "def paddlecartesian_prod(*x): # 飞桨版本的笛卡尔直积函数\n",
    "    z = list(product(x,y))\n",
    "    z = paddle.to_tensor(z)\n",
    "    return z.squeeze(axis=-1)\n",
    "r = paddle.to_tensor([-1, 0, 1])\n",
    "# neighbour_mask = paddlecartesian_prod(r, r, r)\n",
    "\n",
    "r = torch.Tensor([-1, 0, 1])\n",
    "neighbour_mask = torch.cartesian_prod(r, r, r)\n",
    "print(neighbour_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  3.,  4.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 8.,  9., 10.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 5.,  6.,  7.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(5, 3)\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
    "index = torch.tensor([0, 4, 2])\n",
    "x.index_add_(0, index, t)\n",
    "# x.index_add_(0, index, t, alpha=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paddleindex_add(x, dim, index, source): # 飞桨的index_add\n",
    "    # return x # 测试速度\n",
    "    for i in range(len(index)):\n",
    "        x[index[i]] += source[i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[2, 3], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[110, 130, 220],\n",
      "        [60 , 40 , 50 ]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "x = paddle.to_tensor([[10, 30, 20], [60, 40, 50]])\n",
    "index = paddle.to_tensor([[0]])\n",
    "value = 99\n",
    "value = paddle.to_tensor([100,100,200])\n",
    "axis = 0\n",
    "result = paddle.put_along_axis(x, index, value, axis, reduce=\"add\")\n",
    "print(result)\n",
    "# [[99, 99, 99],\n",
    "# [60, 40, 50]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [0])\n",
      "Tensor(shape=[2], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [8, 9])\n",
      "Tensor(shape=[2], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [8, 9])\n"
     ]
    }
   ],
   "source": [
    "# 看issue里面的报错，经验证没有发现问题\n",
    "import paddle\n",
    "\n",
    "# 当label，mask仅有一个元素时，Paddle2.2会报错，现在的Paddle2.3解决了这个问题，不会报错了\n",
    "label = paddle.to_tensor([0])\n",
    "mask = paddle.to_tensor([True], dtype='bool')\n",
    "print(label[mask])\n",
    "\n",
    "\n",
    "# 但是有多个元素时，Paddle2.3怎么又不支持tensor索引了？索引的结果是错的！！\n",
    "label = paddle.to_tensor([0, 8, 9])\n",
    "mask = paddle.to_tensor([False, True, True], dtype='bool')\n",
    "print(label[mask])  # Paddle2.3运行后输出[0, 0]，在Paddle2.2下运行是[8, 9]正常的\n",
    "print(label[[False, True, True]])  # Paddle2.3下这样运行是正常的输出[8, 9]，总之变成Tensor就不对了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6]\n"
     ]
    }
   ],
   "source": [
    "# 看issue里面的花样索引 https://github.com/PaddlePaddle/Paddle/issues/42554\n",
    "# 解决方法就是把多索引改成单索引的组合\n",
    "import paddle\n",
    "import numpy as np\n",
    "\n",
    "bbox_annotation = [[131.27171326, 413.02932739, 163.76470947, 482.08468628, -24.44395447, 11.],\n",
    "                   [166.36415100, 406.51464844, 187.15966797, 465.14657593, -25.40771866, 11.],\n",
    "                   [191.05882263, 388.27362061, 217.05322266, 465.14657593, -24.84239006, 11.],\n",
    "                   [230.05041504, 392.18240356, 256.04483032, 457.32897949, -23.96249008, 11.],\n",
    "                   [257.34454346, 368.72964478, 282.03921509, 442.99673462, -26.11391258, 11.],]\n",
    "bbox_annotation = paddle.to_tensor(bbox_annotation)\n",
    "# bbox_annotation = np.array(bbox_annotation)  # 必须转化为numpy格式才行，但是这样，在计算loss的时候会丢失梯度\n",
    "# bbox_annotation[[0, 1, 2, 3], :]\n",
    "print (bbox_annotation.shape)\n",
    "tmp = bbox_annotation[[0,1,2,3]]\n",
    "tmp\n",
    "### 其他补充信息 Additional Supplementary Information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paddlegather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n",
      "Tensor(shape=[1], dtype=int32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [2]) Tensor(shape=[1], dtype=int32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [3]) Tensor(shape=[1], dtype=int32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [4])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "(InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [8] and the shape of Y = [8, 2]. Received [8] in X is not equal to [2] in Y at i:1.\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\n  [operator < elementwise_add > error]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3daf239c7675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# print(t.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpaddle_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-3daf239c7675>\u001b[0m in \u001b[0;36mpaddle_gather\u001b[0;34m(x, index)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0midx_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx_mk\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0midx_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx_m\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midx_n\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midx_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mx_flatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0my_flatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_flatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/paddle/fluid/dygraph/math_op_patch.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(self, other_var)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mmath_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmath_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpProtoHolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_op_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: (InvalidArgument) Broadcast dimension mismatch. Operands could not be broadcast together with the shape of X = [8] and the shape of Y = [8, 2]. Received [8] in X is not equal to [2] in Y at i:1.\n  [Hint: Expected x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1 == true, but received x_dims_array[i] == y_dims_array[i] || x_dims_array[i] <= 1 || y_dims_array[i] <= 1:0 != true:1.] (at /paddle/paddle/phi/kernels/funcs/common_shape.h:84)\n  [operator < elementwise_add > error]"
     ]
    }
   ],
   "source": [
    "# paddlegather https://gitee.com/paddlepaddle/Paddle/issues/I4QBTN\n",
    "# issue里面提供的例子，跑不通\n",
    "def paddle_gather(x, index):\n",
    "    print(x.shape)\n",
    "    m, n, k = paddle.split(paddle.shape(x), 3)\n",
    "    print(m, n, k)\n",
    "    idx_mk = paddle.arange(end=m * k)\n",
    "    idx_m = idx_mk / k\n",
    "    idx_k = idx_mk % k\n",
    "    idx_n = paddle.gather(index, idx_m)\n",
    "    idx = idx_m * n * k + idx_n * k + idx_k\n",
    "    x_flatten = paddle.flatten(x)\n",
    "    y_flatten = paddle.gather(x_flatten, idx)\n",
    "    ret = paddle.reshape(y_flatten, [m, 1, k])\n",
    "    return ret\n",
    "\n",
    "\n",
    "t = paddle.to_tensor([[1, 2], [3, 4], [0,0]])\n",
    "t = paddle.randn([2,3,4])\n",
    "# print(t.shape)\n",
    "paddle_gather(t, paddle.to_tensor([[0, 0], [1, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle_gather: 0.0023 sec\n"
     ]
    }
   ],
   "source": [
    "# 飞桨组合实现\n",
    "def paddle_gather(x, dim, index):\n",
    "    index_shape = index.shape\n",
    "    index_flatten = index.flatten()\n",
    "    if dim < 0:\n",
    "        dim = len(x.shape) + dim\n",
    "    nd_index = []\n",
    "    for k in range(len(x.shape)):\n",
    "        if k == dim:\n",
    "            nd_index.append(index_flatten)\n",
    "        else:\n",
    "            reshape_shape = [1] * len(x.shape)\n",
    "            reshape_shape[k] = x.shape[k]\n",
    "            x_arange = paddle.arange(x.shape[k], dtype=index.dtype)\n",
    "            x_arange = x_arange.reshape(reshape_shape)\n",
    "            dim_index = paddle.expand(x_arange, index_shape).flatten()\n",
    "            nd_index.append(dim_index)\n",
    "    ind2 = paddle.transpose(paddle.stack(nd_index), [1, 0]).astype(\"int64\")\n",
    "    paddle_out = paddle.gather_nd(x, ind2).reshape(index_shape)\n",
    "    return paddle_out\n",
    "\n",
    "t = paddle.to_tensor([[1, 2], [3, 4]])\n",
    "with Benchmark(\"paddle_gather\"):\n",
    "    paddle_gather(t, 1, paddle.to_tensor([[0, 0], [1, 0]]))\n",
    "# 输出\n",
    "# Tensor(shape=[2, 2], dtype=int32, place=CPUPlace, stop_gradient=True,\n",
    "#        [[1, 1],\n",
    "#         [4, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.gather: 0.0003 sec\n"
     ]
    }
   ],
   "source": [
    "# PyTorch示例：\n",
    "import torch\n",
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "with Benchmark(\"torch.gather\"):\n",
    "    torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]]))\n",
    "# 输出\n",
    "# tensor([[ 1,  1],\n",
    "#         [ 4,  3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index_select\n",
    "感觉这个弄好，应该可以大有可为。\n",
    "但是这个index只能1D吧？ 后来明白，index就是1D的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_select: 0.0002 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
       "       [[1., 2., 3., 4.],\n",
       "        [5., 6., 7., 8.],\n",
       "        [1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "x = paddle.to_tensor([[1.0, 2.0, 3.0, 4.0],\n",
    "                      [5.0, 6.0, 7.0, 8.0],\n",
    "                      [9.0, 10.0, 11.0, 12.0]])\n",
    "index = paddle.to_tensor([0, 1, 1, 2], dtype='int32')\n",
    "index = paddle.to_tensor([0, 1, 0], dtype='int32')\n",
    "out_z1 = paddle.index_select(x=x, index=index)\n",
    "#[[1. 2. 3. 4.]\n",
    "# [5. 6. 7. 8.]\n",
    "# [5. 6. 7. 8.]]\n",
    "with Benchmark(\"index_select\"):\n",
    "    out_z2 = paddle.index_select(x=x, index=index, axis=1)\n",
    "#[[ 1.  2.  2.]\n",
    "# [ 5.  6.  6.]\n",
    "# [ 9. 10. 10.]]\n",
    "out_z1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mask_select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
       "       [1., 5., 6., 9.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "x = paddle.to_tensor([[1.0, 2.0, 3.0, 4.0],\n",
    "                      [5.0, 6.0, 7.0, 8.0],\n",
    "                      [9.0, 10.0, 11.0, 12.0]])\n",
    "mask = paddle.to_tensor([[True, False, False, False],\n",
    "                         [True, True, False, False],\n",
    "                         [True, False, False, False]])\n",
    "out = paddle.masked_select(x, mask)\n",
    "out\n",
    "#[1.0 5.0 6.0 9.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## where已经对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[2, 1], dtype=float64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[8207.98662511  ],\n",
      "        [131073.03168893]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# x is ndarray, shape=(m, n)\n",
    "# torch\n",
    "import numpy as np \n",
    "x = np.ndarray((2, 3))\n",
    "b = torch.tensor(x)\n",
    "bnorm = torch.norm(b, p=2, dim=-1, keepdim=True)\n",
    "# b[bnorm.flatten(), :] \n",
    "\n",
    "\n",
    "# paddle报错\n",
    "a = paddle.to_tensor(x)\n",
    "anorm = paddle.norm(a, p=2, axis=-1, keepdim=True)\n",
    "print(anorm)\n",
    "# a[anorm.flatten(), :] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4367e-04, 6.2378e-02, 9.9805e-01],\n",
      "        [9.9999e-01, 1.5259e-05, 3.9062e-03]], dtype=torch.float64) Tensor(shape=[2, 3], dtype=float64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0.00024367, 0.06237828, 0.99805255],\n",
      "        [0.99999237, 0.00001526, 0.00390622]])\n"
     ]
    }
   ],
   "source": [
    "# x is ndarray, shape=(m, n)\n",
    "# torch\n",
    "b = torch.tensor(x)\n",
    "bnorm = torch.norm(b, p=2, dim=-1, keepdim=True)\n",
    "bn = torch.where(bnorm>=1, b/bnorm, b)\n",
    "\n",
    "# paddle报错，要求 condition 与 x、y 的 shape 一样。\n",
    "a = paddle.to_tensor(x)\n",
    "anorm = paddle.norm(a, p=2, axis=-1, keepdim=True)\n",
    "an = paddle.where(anorm>=1, a/anorm, a)\n",
    "print(bn, an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([1, 4])\n",
      "Tensor(shape=[2, 2], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[1, 2],\n",
      "        [3, 4]])\n",
      "Tensor(shape=[2], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [1, 4])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([[1,2],[3,4]])\n",
    "print(b)\n",
    "print(b[torch.tensor([[True,False],[False,True]])])\n",
    "\n",
    "a = paddle.to_tensor([[1,2],[3,4]])\n",
    "print(a)\n",
    "print(a[paddle.to_tensor([[True,False],[False,True]])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多维索引\n",
    "看到了曙光，可以这样组合来进行多维索引啊！ \n",
    "只要将第一维度的索引使用全量索引即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(range: 0.0000 sec\n",
      "paddle.arange: 0.0012 sec\n",
      "[0, 1, 2]\n",
      "t[i]:\n",
      "Tensor(shape=[3, 4], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0 , 1 , 2 , 3 ],\n",
      "        [4 , 5 , 6 , 7 ],\n",
      "        [8 , 9 , 10, 11]])\n",
      "t[i, j]:\n",
      "Tensor(shape=[3], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [0 , 4 , 11])\n",
      "index : 0.0002 sec\n",
      "Tensor(shape=[3, 4], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[42, 1 , 2 , 3 ],\n",
      "        [42, 5 , 6 , 7 ],\n",
      "        [8 , 9 , 10, 42]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import paddle\n",
    "\n",
    "t = paddle.to_tensor(np.arange(0, 12).reshape(3, 4))\n",
    "i = paddle.to_tensor([0, 0, 1, 2])\n",
    "i = [0, 0, 1, 2]\n",
    "with Benchmark(\"list(range\"):\n",
    "    i = list(range(t.shape[0]))\n",
    "with Benchmark(\"paddle.arange\"):\n",
    "    paddle.arange(t.shape[0])\n",
    "print(i)\n",
    "j = paddle.to_tensor([0, 0, 3])\n",
    "\n",
    "print('t[i]:')\n",
    "print(t[i])\n",
    "print('t[i, j]:')\n",
    "print(t[i, j])\n",
    "with Benchmark(\"index \"):\n",
    "    t[i, j] = 42 \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[i, j]  = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
